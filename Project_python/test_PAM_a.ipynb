{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script for testing the bertopic functionality and classes\n",
    "from bertopic import BERTopic\n",
    "from logging import error\n",
    "import data\n",
    "import conf\n",
    "import pandas as pd\n",
    "import tools\n",
    "import json\n",
    "import model\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import tomotopy as tp\n",
    "\n",
    "paths = conf.get_paths()\n",
    "raw_orgFiles, sdgs_orgFiles = data.get_sdgs_org_files(paths[\"SDGs_inf\"])\n",
    "raw_natureShort, sdgs_nature, index_abstracts = data.get_nature_abstracts()\n",
    "raw_natureExt, sdgs_natureAll, index_full = data.get_nature_files(abstract=True, kw=True, intro=True, body=True, concl=True)\n",
    "raw_pathFinder, sdgs_pathFinder = data.get_sdgs_pathfinder(paths[\"ref\"], min_words=200)\n",
    "raw_extraFiles, sdgs_extra = data.get_extra_manual_files(paths[\"ref\"])\n",
    "raw_healthcare, sdgs_healthcare = data.get_health_care_files(paths[\"ref\"], n_files=100)\n",
    "\n",
    "def prepare_texts(corpus):\n",
    "    newCorpus = []\n",
    "    for text in corpus:\n",
    "        newCorpus.append(\" \".join(tools.tokenize_text(text, lemmatize=False, stem=False ,extended_stopwords=True)))\n",
    "    return newCorpus\n",
    "        \n",
    "# trainFiles = prepare_texts(raw_trainFiles)\n",
    "orgFiles = prepare_texts(raw_orgFiles)\n",
    "extraFiles = prepare_texts(raw_extraFiles)\n",
    "healthcareFiles = prepare_texts(raw_healthcare)\n",
    "natureShort = prepare_texts(raw_natureShort)\n",
    "natureExt = prepare_texts(raw_natureExt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pam = model.PAM_classifier(k1=1, k2=1, rm_top=0)\n",
    "pam.set_conf(paths)\n",
    "\n",
    "trainData = [orgFiles, sdgs_orgFiles]\n",
    "pam.train_model(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainData = [raw_orgFiles + raw_extraFiles + raw_healthcare, sdgs_orgFiles + sdgs_extra + sdgs_healthcare]\n",
    "trainData = [orgFiles + extraFiles + healthcareFiles, sdgs_orgFiles + sdgs_extra + sdgs_healthcare]\n",
    "# trainData = [raw_orgFiles, sdgs_orgFiles]\n",
    "topic_model = model.BERTopic_classifier(paths)\n",
    "\n",
    "# inherit the whole class?\n",
    "\n",
    "# TODO: try to generate a methodology for assigning labels to the training texts in order t oclassify them?\n",
    "topic_model.train_global_model(trainData, seed_topic_list=sdgs_seed_list)\n",
    "# topic_model.load_global_model()\n",
    "# topic_model.map_model_topics_to_sdgs(associated_sdgs=trainData[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.global_model.visualize_barchart(top_n_topics=18, n_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.topics_association = [3, 3, 11, 16, 9, 5, 14, 15, 2, 4, 8, 1, 6, 7, 13, 12, 10]\n",
    "topics, probs = topic_model.global_model.transform(natureShort[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart(top_n_topics=17, n_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics, probs = topic_model.transform(natureExt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = range(60)\n",
    "for doc in docs:\n",
    "    probs_ascii = [\"x{}:{:.3f}\".format(ii, prob) for ii, prob in zip(range(len(list(probs[0]))), probs[doc])]\n",
    "    print(['|'.join(probs_ascii), sdgs_natureAll[doc]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# freq = topic_model.get_topic_info(); freq.head(10)\n",
    "topic_model.visualize_topics()\n",
    "documents = topic_model.get_representative_docs(topic=None) # to understand the\n",
    "topic_model.visualize_distribution(probs[2], min_probability=0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_hierarchy(top_n_topics=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_heatmap(n_clusters=15, width=1000, height=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine with the elbow method to adjust the best number of words per topic\n",
    "topic_model.visualize_term_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINE TUNE THE MODEL FOR BETTER UNDERSTANDING\n",
    "topic_model.update_topics(docs, topics, n_gram_range=(1, 2))\n",
    "new_topics, new_probs = topic_model.reduce_topics(docs, topics, probs, nr_topics=60)\n",
    "topic_model.save(\"my_model\")\t\n",
    "my_model = BERTopic.load(\"my_model\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fbb8ab8bdcac1ab2add1a949848f5c026f8bbe60d997c6f523fcd5fccd91223f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
