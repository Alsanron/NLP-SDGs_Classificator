www.nature.com/npjdigitalmed

ARTICLE

OPEN

Exploratory study examining the at-home feasibility of a
wearable tool for social-affective learning in children with
autism
Jena Daniels 1, Jessey N. Schwartz1, Catalin Voss2, Nick Haber1, Azar Fazel1, Aaron Kline1, Peter Washington2, Carl Feinstein3,
Terry Winograd2 and Dennis P. Wall 1,3,4
Although standard behavioral interventions for autism spectrum disorder (ASD) are effective therapies for social decits, they face
criticism for being time-intensive and overdependent on specialists. Earlier starting age of therapy is a strong predictor of later
success, but waitlists for therapies can be 18 months long. To address these complications, we developed Superpower Glass, a
machine-learning-assisted software system that runs on Google Glass and an Android smartphone, designed for use during social
interactions. This pilot exploratory study examines our prototype tools potential for social-affective learning for children with
autism. We sent our tool home with 14 families and assessed changes from intake to conclusion through the Social Responsiveness
Scale (SRS-2), a facial affect recognition task (EGG), and qualitative parent reports. A repeated-measures one-way ANOVA
demonstrated a decrease in SRS-2 total scores by an average 7.14 points (F(1,13) = 33.20, p = <.001, higher scores indicate higher
ASD severity). EGG scores also increased by an average 9.55 correct responses (F(1,10) = 11.89, p = <.01). Parents reported
increased eye contact and greater social acuity. This feasibility study supports using mobile technologies for potential therapeutic
purposes.
npj Digital Medicine (2018)1:32 ; doi:10.1038/s41746-018-0035-3

INTRODUCTION
Children with autism spectrum disorder (ASD) struggle to
recognize facial expressions, make eye contact, and engage in
social interactions.1,2 An estimated 1 in 68 children have an ASD,
and many can have dramatic improvements if social skills are
taught intensively from an early age.15 Children with ASD have
demonstrated decits in facial processing abilities, such as
distinguishing fear from surprise and identifying subtler emotions.69 Children also struggle with facial engagement and eye
contact.10,11 Teaching these skills to children with autism is
important for social development and is closely linked with
empathy.1216
Todays standard for treatment of these core ASD decits
focuses on a form of behavioral therapy known as applied
behavioral analysis (ABA).17,18 Although ABA therapy is effective in
increasing IQ, improving eye contact, face-to-face gaze, and
emotion recognition, children who receive ABA often struggle to
generalize learned behaviors to natural interactions and are
dependent on prompts.17,19 Therapies called naturalistic developmental behavioral interventions (NDBIs) promote better generalization of newly learned skills due to their integration into the
childs natural everyday interactions.15,20,21 However, the delivery
of behavioral interventions like ABA and NDBIs is bottlenecked by
an increasing imbalance between the availability of behavioral
therapists and the number of children who must receive care.22,23
One of the strongest predictors of greater treatment outcomes
is younger age at entry into behavioral interventions24,25, but

delays in access to therapy leave many children untreated until
after sensitive periods for language and cognitive development
have already passed.26,27 Additionally, waitlists for access to
therapies, such as ABA and NDBIs can be up to 18 months
long.23,25 Consequently, many children with autism are unable to
build such core social skills and subsequently regress towards a
path of isolation.24,28 These issues have compounded into an
urgent need for alternative, ubiquitous mobile methods of
delivery29 that can positively alter the healthcare system and
scale to meet the growing population in need of early
intervention.
To address the complications associated with accessing the
clinical setting and to expedite childrens access to therapy, we
have begun development of a system to deliver therapy at home
using a machine-learning-assisted software system that runs on
Google Glass paired with an Android smartphone, designed for
use in the childs natural environment during social interactions
with friends and family members.3032 It recognizes eight
emotions, as described in detail by Ekman et al.: happiness,
sadness, anger, disgust, surprise, fear, neutral, and contempt
(named meh in child-friendly terms), which are recognized as
theoretically universal emotions.3335 The Glass provides audiovisual feedback to the wearer that corresponds to which of the
eight emotions the Glass recognizes during social interactions
through its outward-facing camera.
Using technology and software for children with autism may
assist children struggling with social anxiety in social

1

Division of Systems Medicine, Department of Pediatrics, Stanford University, Palo Alto, CA, USA; 2Department of Computer Science, Stanford University, Palo Alto, CA, USA;
Department of Psychiatry and Behavioral Sciences, Stanford University, Palo Alto, CA, USA and 4Department of Biomedical Data Science, Stanford University, Palo Alto, CA, USA
Correspondence: Dennis P. Wall (dpwall@stanford.edu)
3

Received: 7 February 2018 Revised: 18 May 2018 Accepted: 25 May 2018

Published in partnership with the Scripps Translational Science Institute

Wearable Social Learning Aid for Autism
J Daniels et al.

2
Table 1.

Participant demographic information

Demographics n = 14

Sub-category

Mean (SD)/percent
(n)

Age (years)

9.57 (3.37)
79.58% (n = 11)

Gender (% male)
Diagnosis

Comorbidity

Race

Ethnicity

ASD diagnosis (DSM-5)

79.58% (n = 11)

Aspergers diagnosis (DSM-IV)

21.42% (n = 3)

Conrmed diagnosis (via ADOS report)

100% (n = 14)

Comorbid diagnoses of ASD/PDD-NOS, ADHD, Generalized anxiety disorder,
clinical depression, and a learning disability

7.14% (n = 1)

Comorbid diagnoses of ASD, ADHD, and dysgraphia

7.14% (n = 1)

Comorbid diagnoses of ASD and ADHD
Only diagnosed with an ASD

14.28% (n = 2)
72.43% (n = 10)

Caucasian/White (%)

42.85% (n = 6)

Asian (%)

50.00% (n = 7)

Native Hawaiian or other Pacic Islander (%)

7.14% (n = 1)

Hispanic/Latino/Spanish origin (%)

7.14% (n = 1)

Non-hispanic/latino (%)

92.86% (n = 13)

1234567890():,;

Clinical evaluations
Social Communication Questionnaire (SCQ73)
Stanford Binet ABIQ76, total standard score
ABIQs for each ASD severity classication

Child behavior checklist (CBCL72)

Multidimensional Social Competence Scale
(MSCS77)

21.64 (6.79)
95.14 (22.36)
Low-functioning ASD severity (N = 4)

92.20 (7.53)

High-functioning ASD severity (N = 5)

118.00 (9.72)

Total problems

65.21 (7.88)

Internalizing problems

64.57 (9.30)

Externalizing problems

58.43 (6.02)

Stress problems
Depressive problems

64.86 (8.14)
63.93 (9.19)

Anxiety problems

65.21 (11.76)

Attention decit/hyperactivity problems

61.93 (10.02)

Oppositional deant problems

59.21 (7.28)

Total score

198.31 (31.13)

Social motivation

26.23 (7.87)

Social inference

25.15 (7.57)

Demonstrating empathic concern
Social knowledge

28.00 (7.48)
28.31 (7.15)

Verbal conversation skills

27.38 (7.76)

Nonverbal conversation skills

33.54 (6.79)

Emotional regulation

29.69 (3.95)

interactions.3638 In addition, incorporating visual, dynamic, and
real-world stimuli can increase learning and greater generalizability to other in vivo interactions.36,39 Studies such as those
conducted by Madsen et al.40 and Liu et al.41, among others42,
have utilized mobile technologies like portable PCs and Google
Glasses to assist children with autism during social interactions via
software for facial recognition, eye tracking, and structured games.
While more recent projects incorporate social interactions with the
use of technology, an important improvement on the use of
computer programs, the limitations of most of these technologybased intervention studies include potentially distracting software,4042 a limited range of participants autism severities,41
adolescent participant populations,40 and highly structured games
(rather than naturalistic interactions).41,42 We seek to improve
upon these approaches with a wearable system that can
seamlessly augment social interactions with social learning cues
in an unobtrusive, naturalistic way. We hypothesize that our
npj Digital Medicine (2018) 32

73.80 (15.95)

Moderate ASD severity (N = 5)

systems ability to provide continuous behavioral therapy outside
of clinical settings will enable faster gains in social acuity, and that
within a limited and self-directed period of use, will permit the
child to engage in increasingly more complex social scenarios on
his/her own.
Our pilot research9,30,43 established smart glasses as a practical
and feasible platform to deliver audiovisual feedback to children
with ASD. Part of the foundation of this pilot work included an
iterative design aspect, where, throughout the study, we
evaluated and compared various interfaces and games. The
humancomputer interaction lessons from our iterative design
process have been documented in Washington et al.43 We created
robust facial expression software31,45,46 and implemented many
design-focused iterations.32,47 The present study expands upon
our previous work and sends our prototype system to the home
environments of children with ASD. In this study, we evaluated the
potential of the Superpower Glass prototype as a wearable
Published in partnership with the Scripps Translational Science Institute

Wearable Social Learning Aid for Autism
J Daniels et al.

3
Table 2.

Interview questions asked during conclusion appointments
Responded yes

Interview questions to parents
(1) Do you feel that additional games and/or more complex games would increase your engagement?

N = 14 (100%)

(2) Did you nd charging the device to be burdensome or challenging?

N = 14 (100%)

(3) Did you use some sort of a reward system to get your child to use the system?

N = 5 (35.7%)

(4) Would you use the system more if the entire experience was gamied?

N = 14 (100%)

(5) During the sessions, did you ever change your facial expression to be more emotive as a result of the emotion recognition
accuracy?

N = 6 (42.9%)

(6) Did you nd that your child made increased eye contact when not wearing the device?

N = 12 (85.7%)

(7) Did you nd that your child made increased social interaction when not wearing the device?
(8) Did you nd that your child exhibited increased emotional recognition when not wearing the device?

N = 7 (50%)
N = 11 (78.6%)

(9) Did you nd that your child increased spontaneous conversation when not wearing the device?

N = 2 (14.3%)

(10) Did you nd that your child showed increased patience when not wearing the device?

N = 4 (28.6%)

(11) Did you nd that your child showed increased empathy when not wearing the device?

N = 6 (42.9%)

(12) Did you nd that using the device resulted in an overall increase in quality family time?

N = 13 (92.9%)

Interview questions to children
N = 12 (85.7%)

(1) Would you want to use this tool in social settings outside of the home?

(2) (Asked only to 10 participants who had siblings) Did you use the device with your siblings?
N = 5 (50%)
(3) Did you ever try to disable to Superpower Glass application on the Android device to access the other features of the phone? N = 7 (50%)
(4) Did you nd the technical component of the system cool?

N = 10 (71.4%)

(5) Did the Google Glass make you interested in the study?

N = 10 (71.4%)

(6) Did you enjoy playing the games provided with the system?

N = 14 (100%)

(7) Do you feel that additional games and/or more complex games would increase your engagement?

N = 14 (100%)

(8) Did you notice the Google Glass heating up when using it?

N = 10 (71.4%)

(9) Did you notice errors in the softwares emotion recognition capabilities?

N = 10 (71.4%)

(10) Would you use the system more if the entire experience was gamied?
(11) Would you prefer a more personalized experience?

N = 14 (100%)
N = 10 (71.4%)

(12) Did you enjoy the free play activity?

N = 11 (78.6%)

(13) Did you enjoy the guess the emotion activity?

N = 13 (92.9%)

(14) Did you enjoy the capture the smile activity?

N = 11 (78.6%)

(15) What was your preferred method of feedback: both audio and visual?

N = 12 (85.7%)

What was your preferred method of feedback: visual feedback only?

N = 2 (14.3%)

What was your preferred method of feedback: audio feedback only?

N = 0 (0%)

therapy intervention that increases social skills, facial affect
recognition, and eye contact for children with autism between
the ages of 3 and 17 years. Additionally, this eld study was
designed to determine feasibility of the t and form factor of the
Glasses, the appropriate dosage as determined by family usage
over several weeks, and the feasibility of sustained use of
Superpower Glass in the home setting.
RESULTS
Between July 2016 and October 2016, 24 participants consented
to participate and attended an intake appointment at Stanford
University. Five families withdrew prior to using the Superpower
Glass system at home or were unable to continue the treatment
portion of the study due to conicts in personal schedules. All ve
of these participants who withdrew prior to using the Superpower
Glass system at home were male, with an average age of 7 years
6 months (SD = 2.51 years), and had an average ABIQ score of 95.8
(median = 106, SD = 27.95). Four of these participants were
Caucasian and one was Asian. The research team excluded ve
additional families who did not comply with the at-home study
procedures, which required families to complete three or more
sessions with Superpower Glass per week, for 20 min per session.
The ve families that were excluded by the research team due to
noncompliance with the required use of the device were also all
Published in partnership with the Scripps Translational Science Institute

male, with an average age of 8 years 6 months (SD = 4.04 years),
and had an average ABIQ score of 74.8 (median = 76, SD = 10.08).
Two of these participants were Caucasian and three were Asian.
This yields a study compliance rate of 73.68%. The following
results are based on the remaining 14 families. Refer to Table 1 for
participant demographics.
The 14 families who complied with the minimum usage
requirements had the device at home for an average of 72 days,
or 10.29 weeks (SD = 5.0 weeks, max = 19.43 weeks, min =
3.86 weeks). In total, we gathered 5726 min of app usage logged
data. Participant mean app usage was 409 min (SD = 266.8 min,
max = 1010 min). Of the 14 families, three families used the device
for 1 month (SD = 1.53 days) for an average of 10.27 sessions per
week (SD = 2.18), two families used the device for more than
1 month but less than 2 months (SD = 12.73 days) for an average
of 9.14 sessions per week (SD = 7.74), ve families used the device
for more than 2 months but less than 3 months (SD = 8.38 days)
for an average of 4.39 sessions per week (SD = 2.50), three families
used the device for more than 3 months but less than 4 months
(SD = 13.08 days) for an average of 3.29 sessions per week (SD
= .71), and one family used it for 4.5 months for an average of
3.76 sessions per week.
We report the clinical implications of the feedback families gave
during the semi-structured interview. Detailed design and user
experience feedback is reported in a previous publication.43 In
npj Digital Medicine (2018) 32

Wearable Social Learning Aid for Autism
J Daniels et al.

4
Table 3.

Statistics from a repeated measures ANOVA analysis of the SRS-2 at intake and at conclusion

SRS-2 subsection T-scores

Mean (SD)
Intake

Sig.
Conclusion

SEM
Intake

Conclusion

SRS total

80.07 (9.531)

72.93 (10.292)

p < .001

2.547

2.751

SRS social awareness

78.07 (11.194)

71.21 (11.544)

p < .001

2.992

3.085

SRS social cognition
SRS communication

74.86 (8.160)
78.93 (10.477)

69.93 (10.594)
72.57 (10.308)

p < .05
p < .001

2.181
2.8000

2.831
2.755

SRS social motivation

68.71 (9.523)

64.79 (9.784)

p < .05

2.545

2.615

SRS autistic mannerisms

83.07 (18.036)

72.07 (11.737)

p < .01

4.820

3.137

summary, families found the system to be engaging, useful, and
fun based on feedback from their conclusion interviews (Table 2;
Notable responses are recorded in Appendix A). According to the
Superpower Glass logged data, families chose evenly between
structured interactive games (Capture the Smile and Guess the
Emotion) and Free Play (51% to 49%). However, activity preference
varied substantially between participant ASD severities based on
both logged data and qualitative feedback. Families whose
children had more social-cognitive decits preferred the structured game modes and chose to run far fewer Free Play sessions.43
Linear regression analysis of game mode selection compared to
ABIQ showed signicant correlations as ABIQ decreased, Free Play
selection decreased and Guess the Emotion selection increased (p
= 0.026 and p = 0.040, respectively).
Specic to the clinical implication of Superpower Glass, 12 of 14
families commented that they had observed an increase in eye
contact from intake to conclusion during the semi-structured
interview.
The mean total SRS-2 score during the intake appointments was
80.07 (SD = 9.53, SEM = 2.55); the mean total SRS-2 score during
the conclusion appointments was 72.93 (SD = 10.29, SEM = 2.75).
Childrens total SRS-2 scores decreased an average of 7.38 points
over the course of the study (F(1,13) = 33.20, p < .001, a higher
score indicates a higher severity of ASD) and there was no
signicant correlation between the decrease in SRS-2 scores to the
number of days the device was at home or to the ASD severity
category of ABIQ (Table 1). Six participants moved from one SRS-2
severity class of autism to a less severe class (four from severe to
moderate, one from moderate to mild, and one from mild
to normal). A repeated-measures one-way ANOVA analysis
showed a signicant decrease in total SRS-2 score from start to
end of the prescribed Glass usage, and for each subsection of the
SRS-2 (Table 3). None of the participants scores increased
between measurements. There was no signicant correlation
between ABIQ, number of therapies enrolled, nor days of
Superpower Glass at home, and points of improvement on the
SRS-2 Total T-score (respectively, p = .108, p = .247, and p = .374).
In addition, the SRS-2 data showed signicant changes preGlass and post-Glass usage on sub-domain questions, including
changes in recognizing intent, social initiation, social interaction,
and eye contact. The Wilcoxon Rank Sum test run on the SRS-2 65
item-level questions showed a nominally signicant change from
intake to conclusion for ve items among the 65 (Table 4).
Due to our iterative design platform for this pilot work, the rst
three study participants did not receive the EGG evaluation at
intake. The remaining 11 of the 14 participants completed the
EGG at intake and conclusion. The 11 participants EGG scores
yielded a signicant increase in emotion labeling accuracy (F(1,10)
= 11.893, p = .006) (Table 5). There was no signicant correlation
between ABIQ, number of therapies enrolled, nor days of
Superpower Glass at home, and points of improvement on the
EGG (p = .499, p = .793, and p = .271, respectively).
npj Digital Medicine (2018) 32

DISCUSSION
Signicant decreases in SRS-2 total scores and subscores,
concomitant increases in emotion recognition measured by EGG,
and responses to semi-structured interviews support the hypothesis that the use of Superpower Glass may be an effective and
practical wearable therapy intervention for children with autism
that can increase social skills, facial affect recognition, and eye
contact. Since neither the number of days with Glass at home nor
the childs ABIQ score were signicantly correlated with improvements on both outcome measures from Pearsons correlation
tests, this initial nding may suggest that the system was equally
effective for all children in our study, irrespective of length of time
with Superpower Glass at home (between 4 and 19 weeks), and
ABIQ score. However, the signicant change demonstrated by
participants from the SRS-2 must be treated with caution, as we
did not include a comparison control group for comparison.
Twelve of the 14 families commented during the semistructured interview that they observed an increase in eye contact
from intake to conclusion. This is also supported by one of the
signicant SRS-2 question items focused on eye contact, which
was included in the Wilcoxon Rank Sum test analysis for changes
from intake to conclusion. The implications of this nding suggest
that Superpower Glass may improve eye contact among children
with autism, although these ndings were not compared to a
control group and thus none of the results are conclusive. This will
be examined in future studies using a control group and using
more quantitative approaches.
Limitations
While this exploratory study provided useful insights to implementation of the study tool at home and the potential of a
wearable behavioral therapy system for children with ASD, there
were limitations to the studys ability to prove clinical efcacy of
our learning aid. Families were required to attend at least three inperson appointments at Stanford University. Stanford University is
situated in an area that is highly enriched for familiarity with
wearables and technology, and as families were required to attend
at least three in-person appointments at Stanford, our sample
population may have resulted in a high concentration of techsavvy families and children who participated. Our results should
be treated cautiously, as families without technical backgrounds
may nd their experience with our system less intuitive, and thus,
further validation of Superpower Glass is necessary to understand
efcacy for the diverse autism population.
Our primary outcome measure, the SRS-2, is parent-reported.
We did not otherwise collect any experimental or measurement
strategies on the participants social skills gains to determine if the
statistically signicant SRS-2 score reduction was due to a parent
placebo effect.48 In our upcoming RCT, as described in Future
Work, we will ameliorate this by including child-directed evaluations conducted by a blinded researcher (such as the Brief
Observation of Social Communication Change49 and NEPSY-II:
Affect Recognition50).
Published in partnership with the Scripps Translational Science Institute

Wearable Social Learning Aid for Autism
J Daniels et al.
Uncorrected sig. Sig. after correction (two-tailed)

5
Table 5. ANOVA analysis on the Emotion Guessing Game from intake
to conclusion
Emotion Guessing Game,
sample size

.033

.055
+.57 (more true) .021

.055

.005

1.79 (.42) 2.36 (.84)
Q45. Focuses his or her attention to where others are looking or listening. Eye contact/joint
attention

.79 (less true)
2.93 (.73) 2.14 (.95)
Social overtures
Q35. Has trouble keeping up with the ow of a normal conversation.

.021
.74 (less true)

.055
.020
.50 (less true)
2.86 (.95) 2.36 (.93)

Sensory sensitivity
Q30. Becomes upset in a situation with lots of things going on.

3.00 (.78) 2.36 (.84)

Social initiation
Q23. Does not join group activities unless told to do so.

.003
.65 (less true)
3.29 (.73) 2.64 (.84)
Q5. Doesnt recognize when others are trying to take advantage of him or Theory of mind
her.

Intake

Mean (SD)
Domain
SRS-2 question

Table 4.

SRS-2 Item-level analysis based on a Wilcoxon Rank Sum test and BenjaminiHochberg correction

Conclusion

Mean change

.033

N = 11

Published in partnership with the Scripps Translational Science Institute

Mean (SD)

p-value

Intake

Conclusion F

28.45
(11.00)

38.00 (2.68) 11.893 .006

The Superpower Glass software was updated several times
throughout the study. Updates to the software included
improvements to camera and network performance, video
recording stability, device connectivity, and visual and audio
feedback response; infrastructural changes for gathering consent
and transferring data; and user experience adjustments to the
presentation of the various options available for therapy sessions.
Though participants started and ended the study with different
versions of Superpower Glass software, there were no signicant
functional changes to the software or instructions to complete the
study procedures that would differentiate their intervention
experience.
The signicant changes on the evaluations found in this study
were not compared to a control group, and therefore we cannot
determine whether it was the system itself, a maturation effect, or
another aspect of the intervention process that resulted in the
changes observed. A follow-on study with a larger, randomized
participant population can determine these effects and conrm
our hypothesis that our Superpower Glass system can lead to
sustained gains in social acuity. Furthermore, while all our other
collected evaluations were peer-reviewed and standardized, EGG
was a novel, unstandardized assessment. There is potential that a
learning effect contributed to the increase in EGG scores for each
participant. Additionally, the same administrator conducted all
EGG assessments and because the EGG emotions are expressed to
the child during an in-person assessment, there was potential for
human error. Finally, baseline EGG scores for the rst three
families were not collected until midway through their participation. This introduces different sample sizes in our two outcome
measures. However, we still see signicant decreases in our other
primary outcome measure, the SRS-2, when we exclude the same
rst three participants from EGG analysis. The same repeated
measures ANOVA analysis on the SRS-2 with these N = 11
participants continues to demonstrate signicance of p < .05 in
all SRS subscores from intake to conclusion, except for the Social
Cognition (p = .071) and Social Motivation (p = .300) subscales.
Lastly, limitations from the hardware included a short battery
life and difculties with charging. Dealing with these limitations
inherently limited our participants study tool usage; however, our
software has been coded in such a way that it can be ported to
other wearable platforms, should a similar kind become available,
therefore ameliorating the above hardware limitations for
potential future studies.
Future work
Further testing and rening needs to be done to validate our
Superpower Glass system as a home behavioral therapy tool. The
results from this exploratory and feasibility study have provided us
with a valuable preliminary understanding of the way that parents
and children with autism engage with our Superpower Glass
system, an important step before beginning a larger randomized
control trial to determine efcacy.51 As such, this study has paved
the way towards creating a more robust protocol via a blinded,
crossover randomized control trial with a cohort of at least 50
families, including additional and standardized outcome measures
to closely assess changes in emotion recognition, eye contact, and
npj Digital Medicine (2018) 32

Wearable Social Learning Aid for Autism
J Daniels et al.

6
Social Feedback Cue
Emoticon and color on
heads up display; audio
of expression recognized

Database
HIPAA-compliant,
encrypted server at
Stanford University

Happy

Child Wearer
Child wears Glass and
interacts with peers and
caregivers outside of
clinical setting for natural
emotions and interactions

Smartphone App
Sensor processor tracks
faces, recognizes action
units, expressions, and

Fig. 1 Overview of the Superpower Glass System. The Android app connects to the Google Glass worn by the child participant. The app
receives facial-tracked data from the Glass camera and computes the emotion expressed by the person the child is interacting with and
returns the emotion as social feedback to the child, all the while recording the social interaction for parentchild review when the session is
complete

social skills that our Glass system may encourage in children with
autism. We intend to benchmark gains in social acuity over the
course of 12 weeks at intake, conclusion, and follow-up to the
Superpower Glass therapy program and run an intention-to-treat
analysis.
METHODS
Participant recruitment and screening methods
Under a Stanford University approved Institutional Review Board protocol,
we identied eligible participants with autism spectrum disorder (ASD) by
referral from the Autism and Developmental Disabilities Clinic and the
Developmental Behavioral Unit of Lucile Packard Childrens Hospital.
Referrals were also generated by conference presentations from Stanford
faculty and staff, educational presentations at ABA therapy organizations,
social media outreach, and press outreach.5255
Informed consent was obtained from all participants in accordance with
our approved IRB, participants then completed a REDcap56 survey and
phone interview to screen for eligibility. The screening questionnaire asked
families to provide general contact, demographic, and diagnostic
information (Table 1). We excluded families if their child: (1) had evidence
of a genetic, metabolic, or infectious etiology based on medical history; (2)
had a history of seizures or other neurological problems; and/or (3) had a
diagnosis of severe mental disorders such as schizophrenia or bipolar
disorder. Eligible participants were asked to complete a phone screen
during which the study manager conducted the Social Communication
Questionnaire (SCQ57). Families were included in the study if: (1) their child
scored > 15 on the SCQ; (2) the child had a medical diagnosis of ASD and
provided the study manager with the diagnostic report, ascertained by an
Autism Diagnostic Observation Schedule (ADOS)58 conducted by a
clinician and based on the Diagnostic and Statistical Manual of Mental
Disorders (DSM-IV or DSM-5) criteria;59,60 and (3) the child was between 3
and 17 years old.

Study tool
The Superpower Glass system is a machine-learning-assisted therapeutic
software system 32,4547 that combines Google Glass (worn by the child)
with a wirelessly linked Android phone application (app), designed to
teach children with autism how to interpret eight universal emotions in
faces3335 (Happy, Sad, Angry, Scared, Surprised, Calm, Disgust, and Meh)
to improve overall social awareness and increase eye contact during social
interactions in the childs natural environment. Figure 1 provides an
overview of the systems architecture.
npj Digital Medicine (2018) 32

During this study, participants were provided game mode options and
feedback selection options at the beginning of each session via the app.
Each game mode is focused on an aspect of emotion recognition and
social interaction, such as emotion identication, eye contact, and/or social
initiation.10 Before the start of a Superpower Glass session (a period of time
when the child and their family member(s) interact with the systems
modes), the parent selects the game mode on the app dashboard, and
then selects the type of feedback that will be provided to the child via
Google Glass. The feedback options are audio feedback labeling the
recognized emotion via the bone-conducting speakers on the Google
Glass, emoticons representing the recognized emotion via the heads-up
display on the Google Glass, or a combination of both audio and
emoticons. When a session is started, the Glasss outward-facing external
camera captures video data of the childs eld of view, which is then
passed to the app and saved at a rate of 30 frames per second. When a
face is in the cameras eld of view expressing one of the eight emotions,
the app automatically classies the emotion and provides real-time
feedback to the child-wearer, via Google Glass, using the mode of
feedback selected at the start of the session. The social cues are displayed
in the Glasss peripheral monitor (as audible words, emoticons, or both,
depending on the feedback selection) and the audio cues use Glasss
bone-conduction speaker. At the end of a session, the parent and child can
review the recorded social interaction videos in the apps dashboard,
enabling a dialog about social interactions. The recorded videos scrub bar
is color-coded, corresponding to when the classier recognized emotions.
Figure 2 demonstrates (a) the feedback emoticons, (b) the game modes,
and (c) the parent review feature within the app.

Emotion expression recognition software
The emotion classication system was constructed by logistic regression
classication that evaluates extracted HOG features61 of a face (captured
by Google Glass outward facing camera), accounts for various lighting
environments,62 and uses neutral subtraction31 to better discriminate
between the eight expressions (Happy, Sad, Angry, Scared, Surprised,
Calm, Disgust, and Meh). The base emotion classication model was
trained on a mix of publicly available databases of labeled facial
expressions (Binghamton University 4D Facial Expression Database; 63
the Bosphorus Database;64 the CMU Pose, Illumination, and Expression
Database;65 the Extended CohnKanade Dataset;66 the Japanese Female
Facial Expression Database;67 the MMI Facial Expression Database;68 and
MultiPIE;69 along with our own data gathered in-lab via another approved
protocol through Stanford University Institutional Review Board). Data
were then augmented by mirroring images and adding Gaussian eld
noise to the face tracker to simulate tracking inaccuracy. To construct userspecic models from the base model, we then employed hierarchical
Published in partnership with the Scripps Translational Science Institute

Wearable Social Learning Aid for Autism
J Daniels et al.

7

Fig. 2 Example of the superpower glasssystem interface. (a) Emoticons are displayed on the Google Glass heads-up display, corresponding
to the emotion recognized by the emotion classier in real-time. (b) The app dashboard on the Android phone allows parents to scroll
through a newsfeed of previously recorded sessions or to start a new session. Parents can select the game mode on the app dashboard.
Selecting Unstructured Activity produces a list of activities for Free Play (the selection does not change the experience). Selecting Guess the
Emotion produces the screen on the right. (c) Parents and children can review a recorded video session on the Android phone app with a
color-coded scrub bar representing when each emotion was expressed and recognized by the system during the video session
Table 6.

Evaluations administered to families during appointments

Instrument name
Social Communication Questionnaire (SCQ

Behaviors measured
73,57

)

Measures general ASD symptomatology using social and emotional behaviors.

Social Responsiveness Scale 2 (SRS-274)

Presence and severity of social impairment.

Child Behavior Checklist (CBCL72)

Behavioral and emotional problems.

Multidimensional Social Competence Scale (MSCS77) Social competence measurement.
Vineland Adaptive Behavior Scales, 2nd edition
(Vineland-II75)

Adaptive behavior in communication, daily living skills, socialization, and motor skills.

Stanford Binet Intelligence Scale (ABIQ76)

Uses two subdomains of verbal/nonverbal sections to determine IQ.

Emotion Guessing Game (EGG)

A 40-question measure developed to assess how well participants can label the eight
emotions examined on a live clinical researcher.

Bayesian domain adaptation,70 which put a Gaussian prior on the
distribution of model coefcients. User-specic models were created
during participants rst study appointment and the process took roughly
ve minutes per family member. This in-house pipeline of the emotion
classier that runs on the Superpower Glass system was engineered for
real-time performance in diverse home settings, with special considerations for conditions, such as specic family members, lighting, and pose
variance. Washington et al.43,47 further details the evaluation of and model
accuracy for the adapted emotion classication model.

Game modes
Free Play: An unstructured activity developed to increase eye contact, enhance
social interactions, and conrm emotion identication in social contexts.
The Glass provides the selected feedback mechanism whenever it
recognizes one of the eight emotions. Families are provided a list of
suggested activities divided into three subcategories (Play, Tell me,
Others). Their choice has no impact on the way the system works during
the activity, but is meant to provide suggestions to families on which
activities to do with their child during a free play session. Once the game
starts, the child receives the selected social cue whenever an emotion is
detected.
Capture the Smile: A semi-structured activity developed to focus on contextual
elements of emotions, increase eye contact, and increase social overtures. 
Capture the Smile is a scavenger hunt game for the child, adapted from
Picard et al.71 The child is prompted by audio cues from the Glass to
provoke a specic emotion in another person. The audio prompt, Find a/
an <emotion> face, uses Glass bone-conducting speakers. The child may
say the selected emotion, act it out, or provide contextual clues around the
emotion in hopes of provoking the other person to express the emotion

Published in partnership with the Scripps Translational Science Institute

they are seeking. In this way, the game can be adapted towards both lowfunctioning and high-functioning children with autism. The app will only
provide the audiovisual feedback to the child-wearer, when the person
interacting with the child expresses the selected emotion. This game lasts
for 3 min, or until the child has successfully evoked 20 emotions, whichever
comes rst.
Guess the Emotion: A structured activity developed to increase eye contact
and emotion identication. Guess the Emotion does not use the emotion
classier software. It is entirely controlled by the app. It challenges the
child to guess the emotion expressed on the face of the person they
interact with. In each round, the parent chooses one of the eight emotions
to emote and then waits for the child to make eye contact and guess
which of the emotions are being expressed. The parent records the childs
response and if the child guesses the correct emotion, the Glass provides
the audiovisual cue corresponding to that emotion. The game is not timed
but scores are recorded and reported for the family to track change from
one session to the next.

Evaluations and in-lab procedures
Each participating family was given the Superpower Glass system after
completing an onboarding process and assessed for changes in behavioral
measures at the end of the treatment period. Participants and the
participants nuclear family members attended in-person appointments at
Stanford University, including an intake appointment, check-in appointments, and a conclusion appointment.
During the intake appointment, the research team collected informed
consent from participants, including any family members who may interact
with the Superpower Glass device. Parents completed several behavioral
evaluations7277 (Table 6). In parallel, the participating child worked with a
npj Digital Medicine (2018) 32

Wearable Social Learning Aid for Autism
J Daniels et al.

8
trained clinical researcher to complete the Nonverbal-Fluid Reasoning and
the Verbal-Knowledge sections of the Abbreviated Binet Intelligence
Quotient (ABIQ)76 to assess IQ. The researcher, who was not blind to the
studys hypothesis, also assessed the childs facial affect recognition using
an in vivo facial affect recognition task (Emotion Guessing Game, EGG), a
secondary outcome measure developed for the purposes of this study,
described in further detail in section Outcome measures.
All families received the Superpower Glass system (Google Glass,
Android Phone with app, cases, and chargers) to use for 2 months upon
completion of their intake questionnaires. Each participating family was
asked to complete at least three 20-minute sessions per week during the
treatment period, and was encouraged to use the system at will beyond
this structured set of sessions. We requested that families complete no
more than two sessions per day. Families attended check-in appointments
at Stanford University during the treatment period, as the familys schedule
permitted. During each check-in, the study manager administered a semistructured interview, as well as the EGG evaluation to track participants
progress with identifying emotions. Data were then pulled from the
familys Superpower Glass system and stored on secure and encrypted
cloud infrastructure for the study team to review.
At the conclusion appointment, the Superpower Glass system was
returned to the study team and parents completed a phenotype
evaluation, described in section Outcome measures, while child
participants completed the EGG. Additionally, we conducted a semistructured interview (Table 2) to derive qualitative feedback on the
software, hardware, and experience. All user interaction data was pulled
and logged from the returned device.

Outcome measures
To assess the efcacy of our system on its ability to improve social skills for
children with ASD, parents completed the Social Responsiveness Scale
(SRS-274) at intake and conclusion. The SRS-2 is a peer-reviewed
standardized measure to examine ASD severity by social interactions. TScores below 60 indicate a Normal range, scores between 60 and 65
indicate a mild ASD range, scores between 65 and 75 indicate a
moderate ASD range, and scores above 75 indicate a severe ASD range.
We evaluated the total SRS-2 t-scores via repeated measures one-way
ANOVA. We also used nonparametric measures on item level SRS-2 data to
determine more granular changes that contributed to the total SRS-2
changes. We evaluated the item level changes with a Wilcoxon Rank Sum
test as way to examine the feature-level contribution to overall change in
the SRS-2 scores, as each questions response options were ordinal (1 = not
true, 2 = sometimes true, 3 = often true, and 4 = almost always true).
To assess the efcacy of our system on its ability to improve childrens
facial affect recognition skills, we used a repeated measures one-way
ANOVA analysis to analyze EGG scores at intake and at conclusion. We
designed EGG to evaluate the childs ability to correctly label emotions
expressed by an examiner, who has been reliably trained to facially express
each emotion in real time. EGG is a pre-set list of eight emotions, listed ve
times each (Happy, Sad, Angry, Afraid, Surprised, Calm, Disgust, and Meh/
contempt). We used a random order generator to set the order of the 40question list, which is then used for all EGG evaluations. During this quick
40-question evaluation, the examiner rst lists the various emotion choices
to the child before beginning the evaluation. Then, the examiner acts out
the expressions, and waits for a guess from the child, who labels the
emotion. The child guesses which emotion the examiner is expressing and
then the examiner records the response and proceeds to the next emotion.
The participant does not receive any feedback during or after evaluation.
Lastly, to examine how (a) ASD functioning level (evaluated via ABIQ
scores), (b) number of therapies enrolled, and (c) days of usage at home
were related to improvements on outcome measures, we ran Pearsons
correlation tests to determine the relationships between each of these
independent variables and points of improvement on (a) SRS total T-scores
from intake to conclusion, and (b) points of improvement on EGG scores
from intake to conclusion.

Data availability
De-identied supporting data, materials, and associated protocols from
this manuscript may be made available from the corresponding author
upon reasonable request.

Code availability statement

ACKNOWLEDGEMENTS
We would like to thank the participating families for their important contributions.
The work was supported in part by funds to D. P. W. from NIH (1R01EB025025-01 and
1R21HD091500-01), the Hartwell Foundation, Bill and Melinda Gates Foundation,
Coulter Foundation, Lucile Packard Foundation, and program grants from Stanfords
Precision Health and Integrated Diagnostics Center (PHIND), Beckman Center, Bio-X
Center, the Predictives and Diagnostics Accelerator Program, the Child Health
Research Institute (CHRI), and Human-Centered AI (HAI). We also acknowledge
generous support from David Orr, Imma Calvo, Bobby Dekesyer, and Peter Sullivan.
In-kind material grants included a gift from Google (35 units of Google Glass version
1) and Amazon Web Services Founder Support.

AUTHOR CONTRIBUTIONS
J. D. and J. S. performed study design data acquisition, curation, and analysis and cowrote the manuscript. C. V. and N. H. developed the core emotion recognition
software, built the rst version of the Superhero Glass system, participated in study
design, methods development, analysis and edited the manuscript. A. F., A. K., and P.
W. worked on the emotion recognition software and app design and edited the
manuscript. C. F. participated in study design, outcome measure analysis, and edited
the manuscript. T. W. provided direction on the humancomputer interface design
and study design and edited the manuscript. D. P. W. directed the study, performed
study methods development, results analysis, and co-wrote the manuscript. All
authors approved the nal version of the manuscript.

ADDITIONAL INFORMATION
Supplementary information accompanies the paper on the npj Digital Medicine
website (https://doi.org/10.1038/s41746-018-0035-3).
Competing interests: The authors declare no competing interests.
Publisher's note: Springer Nature remains neutral with regard to jurisdictional claims
in published maps and institutional afliations.

REFERENCES
1. Christensen, D. L. et al. Prevalence and characteristics of autism spectrum disorder among children aged 8 yearsautism and developmental disabilities
monitoring network, 11 sites, United States, 2012. Mmwr. Surveill. Summ. 65, 123
(2016).
2. Christensen, D. L. et al. Prevalence and characteristics of autism spectrum disorder among 4-year-old children in the autism and developmental disabilities
monitoring network. J. Dev. Behav. Pediatr. 37, 18 (2016).
3. Buescher, A. V., Cidav, Z., Knapp, M. & Mandell, D. S. Costs of autism spectrum
disorders in the United Kingdom and the United States. JAMA Pediatr. 168,
721728 (2014).
4. Nicholas, J. S. et al. Prevalence and characteristics of children with autismspectrum disorders. Ann. Epidemiol. 18, 130136 (2008).
5. Robins, D. L. Prevalence counts: commentary on Prevalence and characteristics
of autism spectrum disorder among 4-year-old children in the autism and
developmental disabilities monitoring network. J. Dev. Behav. Pediatr. 37, 8082
(2016).
6. Fridenson-Hayo, S. et al. Basic and complex emotion recognition in children with
autism: cross-cultural ndings. Mol. Autism 7, 52 (2016).
7. Harms, M. B., Martin, A. & Wallace, G. L. Facial emotion recognition in autism
spectrum disorders: a review of behavioral and neuroimaging studies. Neuropsychol. Rev. 20, 290322 (2010).
8. Ozonoff, S., Pennington, B. F. & Rogers, S. J. Are there emotion perception decits
in young autistic children? J. Child Psychol. Psychiatry 31, 343361 (1990).
9. Daniels, J. H. Testing feasbilitiy of a wearable behavioral aid for social learning in
children with autism. Appl. Clin. Inform 9, 129140 (2018).
10. Baron-Cohen, S., Golan, O. & Ashwin, E. Can emotion recognition be taught to
children with autism spectrum conditions? Philos. Trans. R. Soc. Lond. B 364,
35673574 (2009).
11. Corden, B., Chilvers, R. & Skuse, D. Avoidance of emotionally arousing stimuli
predicts social-perceptual impairment in Aspergers syndrome. Neuropsychologia
46, 137147 (2008).
12. Besel, L. D. & Yuille, J. C. Individual differences in empathy: the role of facial
expression recognition. Pers. Individ. Differ. 49, 107112 (2010).
13. Howlin, P., Goode, S., Hutton, J. & Rutter, M. Adult outcome for children with
autism. J. Child Psychol. Psychiatry 45, 212229 (2004).

Code is available from the corresponding author upon reasonable request.
npj Digital Medicine (2018) 32

Published in partnership with the Scripps Translational Science Institute

Wearable Social Learning Aid for Autism
J Daniels et al.

9
14. Landa, R. J., Holman, K. C. & Garrett-Mayer, E. Social and communication development in toddlers with early and later diagnosis of autism spectrum disorders.
Arch. Gen. Psychiatry 64, 853864 (2007).
15. Schreibman, L. et al. Naturalistic developmental behavioral interventions:
empirically validated treatments for autism spectrum disorder. J. Autism Dev.
Disord. 45, 24112428 (2015).
16. von Hofsten, C. & Gredebck, G. The role of looking in social cognition: perspectives from development and autism. Social Cognition: Development, Neuroscience and Autism. (Wiley-Blackwell: (2008).
17. Lovaas, O. I. Teaching individuals with developmental delays: basic intervention
techniques. ERIC (Pro-Ed, 2003).
18. Maglione, M. A. et al. Nonmedical interventions for children with ASD: recommended guidelines and further research needs. Pediatrics 130(Suppl. 2),
S169S178 (2012).
19. Lovaas, O. I. Behavioral treatment and normal educational and intellectual
functioning in young autistic children. J. Consult. Clin. Psychol. 55, 39 (1987).
20. Ingersoll, B., Meyer, K., Bonter, N. & Jelinek, S. A comparison of developmental
social-pragmatic and naturalistic behavioral interventions on language use and
social engagement in children with autism. J. Speech Lang. Hear. Res. 55,
13011313 (2012).
21. Ingersoll, B. & Schreibman, L. Teaching reciprocal imitation skills to young children with autism using a naturalistic behavioral approach: effects on language,
pretend play, and joint attention. J. Autism Dev. Disord. 36, 487505 (2006).
22. Bernier, R., Mao, A. & Yen, J. Psychopathology, families, and culture: autism. Child
Adolesc. Psychiatr. Clin. N. Am. 19, 855867 (2010).
23. Wiggins, L. D., Baio, J. & Rice, C. Examination of the time between rst evaluation
and rst autism spectrum diagnosis in a population-based sample. J. Dev. Behav.
Pediatr. 27, S79S87 (2006).
24. Dawson, G. Early behavioral intervention, brain plasticity, and the prevention of
autism spectrum disorder. Dev. Psychopathol. 20, 775803 (2008).
25. Mazurek, M. O. et al. Age at rst autism spectrum disorder diagnosis: the role of
birth cohort, demographic factors, and clinical features. J. Dev. Behav. Pediatr. 35,
561569 (2014).
26. Nash, J. M. Fertile minds. Time 149, 4856 (1997).
27. Phillips, D. A. & Shonkoff, J. P. From Neurons to Neighborhoods: The Science of Early
Childhood Development (Washington, D.C.: National Academies Press, 2000).
28. Dawson, G. & Bernier, R. A quarter century of progress on the early detection and
treatment of autism spectrum disorder. Dev. Psychopathol. 25, 14551472 (2013).
29. Stark, D. E., Kumar, R. B., Longhurst, C. A. & Wall, D. P. The quantied brain: a
framework for mobile device-based assessment of behavior and neurological
function. Appl. Clin. Inform. 7, 290298 (2016).
30. Daniels, J. et al. Feasibility testing of a wearable behavioral aid for social learning
in children with autism. Appl. Clin. Inform. 9, 129140 (2018).
31. Haber, N., Voss, C., Fazel, A., Winograd, T. & Wall, D. P. A practical approach to realtime neutral feature subtraction for facial expression recognition. In Proc. 2016
IEEE Winter Conference on Applications of Computer Vision (WACV) 19 (Lake
Placid, NY: IEEE, 2016).
32. Voss, C. et al. Superpower glass: delivering unobtrusive real-time social cues in
wearable systems. In Proc. 2016 ACM International Joint Conference on Pervasive
and Ubiquitous Computing: Adjunct 12181226 (Heidelberg, Germany: ACM, 2016).
33. Ekman, P. et al. Universals and cultural differences in the judgments of facial
expressions of emotion. J. Pers. Soc. Psychol. 53, 712717 (1987).
34. Matsumoto, D. Scalar ratings of contempt expressions. J. Nonverbal Behav. 29,
91104 (2005).
35. Matsumoto, D. & Ekman, P. The relationship among expressions, labels, and
descriptions of contempt. J. Pers. Soc. Psychol. 87, 529 (2004).
36. Grynszpan, O., Weiss, P. L., Perez-Diaz, F. & Gal, E. Innovative technology-based
interventions for autism spectrum disorders: a meta-analysis. Autism 18, 346361
(2014).
37. Lubas, M., Mitchell, J. R. & De Leo, G. Augmentative and alternative communication solutions and autism. in Comprehensive Guide to Autism 10811096
(Springer-Verlag New York, 2014).
38. Pennington, R. C. Computer-assisted instruction for teaching academic skills to
students with autism spectrum disorders: a review of literature. Focus Autism
Other Dev. Disabl. 25, 239248 (2010).
39. Preis, J. The effect of picture communication symbols on the verbal comprehension of commands by young children with autism. Focus Autism Other Dev.
Disabl. 21, 194208 (2006).
40. Madsen, M., El Kaliouby, R., Goodwin, M. & Picard, R. Technology for just-in-time
in-situ learning of facial affect for persons diagnosed with an autism spectrum
disorder. in Proc. 10th International ACM SIGACCESS Conference on Computers and
Accessibility 1926 (New York, NY: ACM, 2008).
41. Liu, R., Salisbury, J. P., Vahabzadeh, A. & Sahin, N. T. Feasibility of an autismfocused augmented reality smartglasses system for social communication and
behavioral coaching. Front. Pediatr. 5, 145 (2017).

Published in partnership with the Scripps Translational Science Institute

42. Virnes, M., Krn, E. & Vellonen, V. Review of research on children with autism
spectrum disorder and the use of technology. J. Spec. Educ. Technol. 30, 1327 (2015).
43. Washington, P. et al. SuperpowerGlass: a wearable aid for the at-home therapy of
children with autism. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 1, 112
(2017).
44. Daniels, J. et al. 5.13 Design and efcacy of a wearable device for social affective
learning in children with autism. J. Am. Acad. Child Adolesc. Psychiatry 56, S257
(2017).
45. Haber, N., et al. A practical approach to real-time neutral feature subtraction for
facial expression recognition. In IEEE International Conference on Computer Vision
(Piscataway, NJ: IEEE 2015).
46. Voss, C. E. A. Automated discovery of facial action units using deep convolutional
neural networks. In IEEE International Conference on Computer Vision (Piscataway,
NJ: IEEE 2015).
47. Washington, P. V. et al. A wearable aid for the at-home therapy of children with
autism. In Proc. 2016 CHI Conference Extended Abstracts on Human Factors in
Computing Systems, 23482354 (San Jose, CA: ACM, 2016).
48. Jones, R. M., Carberry, C., Hamo, A. & Lord, C. Placebo-like response in absence of
treatment in children with Autism. Autism Res. 10(9), 15671572 (2017).
49. Kitzerow, J., Teufel, K., Wilker, C. & Freitag, C. M. Using the brief observation of
social communication change (BOSCC) to measure autismspecic development.
Autism Res. 9, 940950 (2016).
50. Brooks, B. L., Sherman, E. M. & Strauss, E. NEPSY-II: a developmental neuropsychological assessment. Child Neuropsychol. 16, 80101 (2009).
51. Gupta, S. K. Intention-to-treat concept: a review. Perspect. Clin. Res. 2, 109 (2011).
52. Hoshaw, L. Google Glass opped. But kids with autism are using it to recognize
emotions. in KQED Science (KQED INC., San Francisco, CA: KQED Inc., 2016).
53. News, C. How Google Glass could help children with autism. In CBS News (CBS
Interactive Inc., New York, NY: CBS Interactive Inc., 2016).
54. Pettitt, J. A new use for Google Glass: helping children with autism understand
emotion. In CNBC (CNBC LLC, New York, NY: CNBC LLC, 2016).
55. Press, A. Google Glass could change the way autistic kids read faces. In New York
Post (NYP Holdings, New York, NY: NYP Holdings, Inc., 2016).
56. Harris, P. A. et al. Research electronic data capture (REDCap)a metadata-driven
methodology and workow process for providing translational research informatics support. J. Biomed. Inform. 42, 377381 (2009).
57. Blte, S., Holtmann, M. & Poustka, F. The Social Communicaton Questionnaire
(SCQ) as a screener for autism spectrum disorders: additional evidence and crosscultural validity. J. Am. Acad. Child Adolesc. Psychiatry 47, 719720 (2008).
58. Lord, C. et al. The Autism Diagnostic Observation ScheduleGeneric: a standard
measure of social and communication decits associated with the spectrum of
autism. J. Autism Dev. Disord. 30, 205223 (2000).
59. Association, A.P. Diagnostic and Statistical Manual of Mental Disorders (DSM-5)
(Arlington, VA: American Psychiatric Publishing Incorporated, 2013).
60. DSM-IV., A.P.A.T.F.o. DSM-IV Draft Criteria (Arlington, VA: American Psychiatric
Publishing Incorporated, 1993).
61. Dalal, N. & Triggs, B. Histograms of oriented gradients for human detection. in
IEEE Computer Society Conference on Computer Vision and Pattern Recognition,
2005. CVPR 2005, Vol. 1, 886893 (San Diego, California: IEEE, 2005).
62. Tan, X. & Triggs, B. Enhanced local texture feature sets for face recognition under
difcult lighting conditions. IEEE Trans. Image Process. 19, 16351650 (2010).
63. Yin, L., Chen, X., Sun, Y., Worm, T. & Reale, M. A high-resolution 3D dynamic facial
expression database. in 8th IEEE International Conference on Automatic Face &
Gesture Recognition, 2008. FG'08. 16 (Amsterdam, Netherlands: IEEE, 2008).
64. Savran, A., et al. Bosphorus database for 3D face analysis. in European Workshop
on Biometrics and Identity Management 4756 (Berlin, Heidelberg: Springer, 2008).
65. Sim, T., Baker, S. & Bsat, M. The CMU pose, illumination, and expression (PIE)
database. in Proc. Fifth IEEE International Conference on Automatic Face and
Gesture Recognition, 5358 (Washington, D.C.: IEEE, 2002).
66. Lucey, P., et al. The extended cohn-kanade dataset (ck+): a complete dataset for
action unit and emotion-specied expression. in 2010 IEEE Computer Society
Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),
94101 (San Francisco, CA: IEEE, 2010).
67. Lyons, M., Akamatsu, S., Kamachi, M. & Gyoba, J. Coding facial expressions with
gabor wavelets. In Proc. Third IEEE International Conference on Automatic Face and
Gesture Recognition, 200205 (Nara, Japan: IEEE, 1998).
68. Pantic, M., Valstar, M., Rademaker, R. & Maat, L. Web-based database for facial
expression analysis. In IEEE International Conference on Multimedia and Expo,
2005. ICME 2005. 5 pp. (Amsterdam, Netherlands: IEEE, 2005).
69. Gross, R., Matthews, I., Cohn, J., Kanade, T. & Baker, S. Multi-pie. Image Vision
Comput. 28, 807813 (2010).
70. Finkel, J. R. & Manning, C. D. Hierarchical bayesian domain adaptation. In Proc.
Human Language Technologies: The 2009 Annual Conference of the North American
Chapter of the Association for Computational Linguistics 602610 (Boulder, CO:
Association for Computational Linguistics, 2009).

npj Digital Medicine (2018) 32

Wearable Social Learning Aid for Autism
J Daniels et al.

10
71. El Kaliouby, R., Picard, R. & BaronCohen, S. Affective computing and autism. Ann.
N. Y. Acad. Sci. 1093, 228248 (2006).
72. Achenbach, T. M. & Rufe, T. M. The Child Behavior Checklist and related forms
for assessing behavioral/emotional problems and competencies. Pediatr. Rev. 21,
265271 (2000).
73. Allen, C., Silove, N., Williams, K. & Hutchins, P. Validity of the social communication questionnaire in assessing risk of autism in preschool children with developmental problems. J. Autism Dev. Disord. 37, 12721278 (2007).
74. Constantino, J. N. & Gruber, C. P. Social Responsiveness Scale, 2nd edn (SRS-2).
(Western Psychological Services, Los Angeles, CA, 2012).
75. Perry, A., Flanagan, H. E., Dunn Geier, J. & Freeman, N. L. Brief report: The Vineland
Adaptive Behavior Scales in young children with autism spectrum disorders at
different cognitive levels. J. Autism Dev. Disord. 39, 10661078 (2009).
76. Roid, G. H. Stanford-Binet Intelligence Scales. (Riverside Publishing: Itasca, IL, 2003).
77. Yager, J. & Iarocci, G. The development of the multidimensional social competence scale: a standardized measure of social competence in autism spectrum
disorders. Autism Res. 6, 631641 (2013).

npj Digital Medicine (2018) 32

Open Access This article is licensed under a Creative Commons
Attribution 4.0 International License, which permits use, sharing,
adaptation, distribution and reproduction in any medium or format, as long as you give
appropriate credit to the original author(s) and the source, provide a link to the Creative
Commons license, and indicate if changes were made. The images or other third party
material in this article are included in the articles Creative Commons license, unless
indicated otherwise in a credit line to the material. If material is not included in the
articles Creative Commons license and your intended use is not permitted by statutory
regulation or exceeds the permitted use, you will need to obtain permission directly
from the copyright holder. To view a copy of this license, visit http://creativecommons.
org/licenses/by/4.0/.

 The Author(s) 2018

Published in partnership with the Scripps Translational Science Institute

