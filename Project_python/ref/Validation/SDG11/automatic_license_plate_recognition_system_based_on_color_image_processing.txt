Automatic License Plate Recognition System Based on
Color Image Processing
Xifan Shi1, Weizhong Zhao 2, and Yonghang Shen 2
1

College of Computer Science and Technology, Zhejiang University,
2 Department of Physics, College of Science, Zhejiang University,
310027, Hangzhou, Zhejiang, China
zjufan@hotmail.com, physyh@zju.edu.cn

Abstract. A License plate recognition (LPR) system can be divided into the following steps: preprocessing, plate region extraction, plate region thresholding,
character segmentation, character recognition and post-processing. For step 2, a
combination of color and shape information of plate is used and a satisfactory
extraction result is achieved. For step 3, first channel is selected, then threshold
is computed and finally the region is thresholded. For step 4, the character is
segmented along vertical, horizontal direction and some tentative optimizations
are applied. For step 5, minimum Euclidean distance based template matching
is used. And for those confusing characters such as '8' & 'B' and '0' & 'D', a special processing is necessary. And for the final step, validity is checked by machine and manual. The experiment performed by program based on aforementioned algorithms indicates that our LPR system based on color image processing is quite quick and accurate.

1 Introduction
The automatic identification of vehicles has been in considerable demand especially
with the sharp increase in the vehicle related crimes and traffic jams. It can also play a
crucial role in security zone access control, automatic toll road collection and intelligent traffic management system. Since the plate can identify a car uniquely, it is of
great interest in recent decade in using computer vision technology to recognize a car
and several results have been achieved [2-14].
A typical LPR system can be divided into the following modules: preprocessing
(including image enhancement and restoration), plate region extraction, plate region
thresholding, character segmentation, character recognition and post-processing (validity checking). The first two modules, which only concern the shape and back/fore
ground color of a plate and irrespective of character set in a plate, are the front end of
the system. Module 4 and 5, on the contrary, are related to character set in a plate and
regardless of the shape and back/fore ground color of a plate, so they are the back end
of the system. Module 3, however, should take the shape and back/fore ground color
of a plate as well as character set in a plate into consideration. Therefore, it is hard to
say which end it can be categorized into.
To develop an automatic recognition system of a car plate, a stable recognition of a
plate region is of vital importance. Techniques such as edge extraction [1][6], Hough
O. Gervasi et al. (Eds.): ICCSA 2005, LNCS 3483, pp. 1159  1168, 2005.
 Springer-Verlag Berlin Heidelberg 2005

1160

X. Shi, W. Zhao, and Y. Shen

transformation [7] and morphological operations [8] have been applied. An edgebased approach is normally simple and fast. However, it is too sensitive to the unwanted edges, which may happen to appear in the front of a car. Therefore, this
method cannot be used independently. Using HT is very sensitive to deformation of a
plate boundary and needs much memory. Though using gray value shows better performance, it still has difficulties recognizing a car image if the image has many similar parts of gray values to a plate region, such as a radiator region [11][12]. Morphology has been known to be strong to noise signals, but it is rarely used in real time
systems because of its slow operation. So in recent years, color image processing
technology [4][5] is employed to overcome these disadvantages. First, all of the plate
region candidates are found by histogram. After that, each one is verified by comparing its WHR (Width to Height Ratio), foreground and background color with current
plate standard and eliminated if it is definitely not of plate region. And finally, for
each survivor, an attempt to read plate information is made by invoking the back end.
In the back end, first channel is selected and the plate region is thresholded in the
selected channel. And then, each character is extracted by histogram and some optimizations such as the merge of unconnected character (i.e. Chuan, or ), the removal of space mark, frame and pin, the correction of top and bottom coordinates in y
direction and tilt correction are done during this phase. Next, each character is recognized by using minimum Euclidean distance based template matching since it's more
noise tolerant than structural analysis based method [2][3]. And for those confusing
characters, '8' & 'B' and '0' & 'D', for instance, a special processing is necessary to
improve the accuracy. Finally, validity checking is performed against vehicle related
crimes.

2 Plate Region Extraction
In principle, image should first be preprocessed, namely, enhanced and restored. But
the experiment shows that it doesn't deserve its relatively heavy computational cost,
so this step is skipped.
The basic idea of extraction of a plate region is that the color combination of a
plate (background) and character (foreground) is unique and this combination occurs
almost only in a plate region [14]. The correctness of this assumption is proved by the
success of plate region extraction.
Altogether there are 4 kinds of plates in China mainland. They are yellow background and black characters plate for oversize vehicle, blue background and white
characters plate for light-duty vehicle, white background and black or red characters
plate for police or military vehicle, black background and white characters plate for
vehicle of embassy, consulate and foreigners. At first, RGB model is used to classify
all the pixels into the following 6 categories: blue, white, yellow, black, red and other,
but unfortunately it fails because of the wide RGB value difference under different
illumination. So HLS model is introduced, and this time the desired result is achieved,
but it is too slow, namely, it takes PIII 1G roughly 1 second to processing a
1024X768 photo. Clearly, the bottleneck is the conversion from RGB value to HLS
value while the key to its success is insensitivity under different illumination. Naturally, an ideal algorithm must retain this insensitivity under different illumination

Automatic License Plate Recognition System Based on Color Image Processing

1161

while eliminating the conversion between the two color models. Hence, the pixels are
classified into 13 categories instead of 6 according to variance of illumination in the
RGB domain. They are dark blue, blue, light blue, dark yellow, yellow, light yellow,
dark black, black, gray black, gray white, white, light white and other. Here, red is not
take into account because this color appears only once in the center or right part of the
police or military vehicle plates whose dominant character color is black. Thus, it is
enough to identify the plate by checking the black pixels. The speed is increased to
0.5 second per photo while the correct extraction rate remains the same to HLS. But,
that's not enough. Actually, the dot and line interlace scan method is used and the time
cost is reduced to 1/4 of the non-interlaced one. After the plate is extracted, the region
is verified by its shape, i.e. WHR. In China mainland, there are three WHR values,
which are 3.8 for police or military vehicle plates, 2.0 for rear edition of oversize
vehicle plate and 3.6 for others. Because 3.6 and 3.8 is too close, they are merged into
one. So if the WHR of the extracted plate is sufficiently close to 3.7 or 2.0, the verification is passed.
According to Amdahl's law, frequent case should be favored over the infrequent
case. In China mainland, the most common plate is white characters with blue background. Therefore, plate is first tried to be recognized as a white blue pair, then as a
black yellow pair, next as a white black pair and finally as a black white pair.
Taking a white blue pair for example, this process can be illustrated as follows.

Fig. 1. Extraction of a plate region in vertical

As shown in Figure 1, the whole image is scanned and only the number of dark
blue pixels exceeds the given threshold, say 1000, so it can be deduced that it is a dark
blue background plate. Thereby, the plate region in vertical direction is identified by
thresholding the histogram of dark blue pixels.
It is evident that the only candidate is the middle one (For the top, the number of
lines where number of dark blue pixels exceeds the threshold is too small and thus
omitted. If two adjacent plate regions are sufficiently close, then they are merged into
one.). In addition, owing to the favor of frequent case and the fact that the plate region
is generally occurred in the lower part of an image, the scan is done from bottom to
top and hence the middle one is first found. The extracted one is in Figure 2. Similarly, by thresholding in horizontal direction, the plate region is obtained, as illustrated in Figure 3.

1162

X. Shi, W. Zhao, and Y. Shen

Fig. 2. Extraction of a plate region in horizontal

Fig. 3. The extracted plate region

To confirm the extraction, the shape or terminologically WHR is examined [2][3].
Here, it is 310/85=3.65, sufficiently close to 3.7, so the verification is passed.

3 Character Segmentation and Recognition
3.1 Thresholding
The thresholding procedure should introduce as little noise as possible, since subsequent
steps may be seriously affected by a poor thresholding algorithm. Also, because the
lighting conditions vary widely over a plate, locally adaptive thresholding is required.
Empirical methods are devised and they succeed in thresholding the plate region.
There are a variety of threshold algorithms, but the experiments show that "simple
is the best", if considering both speed and accuracy, so bimodal histogram segmentation [13] is introduced. As Figure 4 shows, if the pixels of objects form one of its
peaks, while pixels of the background form another peak, then the histogram is called
bimodal. It is the case provided that an image consists of objects of approximately the
same gray level that differs from the gray level of the background. Fortunately, this
condition is satisfied, for the color of characters, or, the object, is almost the same and
the color of the background of the plate region is also almost the same, which makes
this simple segmentation algorithm works. Since there are three (R, G and B) channels in an image, the channel is selected by the largest standard deviation of the three.
Larger standard deviation means longer distance between the two peaks while longer
distance between the two peaks means the clearer division between background and
object and less sensitive to the noise introduced by thresholding. In the case of the
plate region in Figure 3, the standard deviations in red, green, blue channels are 74.57,
72.51, 59.98, respectively, so the red channel is selected for thresholding. This is
reasonable, because the background is blue and the object is white, which has blue
component and naturally, standard deviation in the blue channel must be the smallest.
Without loss of generality, it is assumed that the object is white and the background is black before thresholding (If not, the color is reversed and this process is
only needed for black yellow pair and black white pair). It can be proved that after
thresholding, the number of white pixel is 68%~85% of the plate region. Suppose V is
the value making 85% of the plate become white and U is the average value of the
remaining. Then threshold value is U minus DetalV, which is from 5 to 10. Correct
thresholding is accomplished by this rule of thumb.

Automatic License Plate Recognition System Based on Color Image Processing

1163

Fig. 4. Bimodal histogram

3.2 Segmentation
First, according to its WHR, the plate is classified as either double line or single line.
The threshold is 1/10 and 1/6 of the width of the plate for the former and the latter,
respectively. Then the line whose number of black pixels exceeds the threshold is
selected, and if two adjacent selected regions are sufficiently close, then they are
merged into one. Next, the WHR of each segmented region is verified, if it is too
large, it is discarded as frame. This process is shown in Figure 5.
Similar process (including threshold acquisition, selection, merge and discard) can
be done in horizontal direction, as illustrated in Figure 6 and 7. The characters are
segmented, but the performance is not quite satisfactory, and therefore some optimizations are carried out during this stage.

Fig. 5. Segmentation in vertical direction

Fig. 6. Segmentation in horizontal direction

1164

X. Shi, W. Zhao, and Y. Shen

Fig. 7. Segmented characters

Removal of Space Mark. The space of the second and the third character is much
larger than that of any other adjacent characters, which can be formalized into the
following rule of thumb:
The ratio of the largest space to the second largest space between the adjacent
characters is 1.25~1.45.

Fig. 8. Mis-segmented characters (due to space mark)

This rule is helpful in removing the space mark, as illustrated in Figure 8. After
segmentation, 8 characters are found including the space mark, the third character.
The largest space is 55 while the second largest space is 53. The ratio is 55 / 53 =
1.04, not within the range of 1.25~1.45. It is suspicious of the existence of space
mark. If it is indeed the case, 55 must be the second largest space and the largest
space is from 69 (1.25X55=68.75) to 80 (1.45X55=79.75). By addition of the adjacent
number, it is obvious that only 35+36=71 is within that range. Hence, the third character is probably the space mark. Its histogram in vertical direction shows that the
pixel is concentrated on the center part, so it must the space mark and removed.
Merge of Unconnected Character. The first one on the plate of China mainland, the
abbreviation for province, is a Chinese character and all characters are connected
except for Chuan, necessitating a special process. A case in point is shown in Figure
9. The character Chuan is segmented into its three strokes, which must be merged.
The largest space is 148 while the second largest space is 113. The ratio is 148 / 113 =
1.31 within the range of 1.25~1.45. So the fourth character should be the second character, which means the first character is a union of the first three characters. Merge is
done in right to left order until the WHR of the merged character is within

Fig. 9. Mis-segmented Chinese character (due to disconnectivity)

Automatic License Plate Recognition System Based on Color Image Processing

1165

normal range. In this case, only by merge the first three characters can the WHR be
satisfied, which leads to the correct merge of the unconnected character Chuan.
Correction of Top and Bottom. Coordinates. Because plate may be tilted, the top and
bottom coordinates are probably not correct (see in Figure 7). This process is required
and the coordinates of each character are rectified by utilizing its histogram in vertical
direction. The correction result of the plate in Figure 7 is shown in Figure 10.

Fig. 10. Correction result

Removal of Frame. In Figure 10, there's some noise in the lower right part of the last
character, which comes from the frame. But the last character is a digit, which is connected. This property makes the removal of frame possible and the comparison is
shown in Figure 11.

Fig. 11. Removal of frame

Fig. 12. Degraded top coordinate correction due to pin

Removal of Pin. Because of the pin, on some occasions, the results of the correction
of the top and bottom coordinates are degraded, rather than upgraded, as illustrated in
Figure 12. But owing to the linearity of the top/bottom coordinates, the top/bottom
coordinate of each character must between the top/bottom coordinates of their left and
right neighbor. In Figure 12, it is beyond doubt that the top coordinate of the second is
large than that of the first and third, so the top coordinate is substituted by the average
of that of the first and third and thus the pin is successfully removed. Pin on the sixth
can be removed in the same way and the result is shown in Figure 13.

Fig. 13. Pin removal

1166

X. Shi, W. Zhao, and Y. Shen

Tilt Correction. For every segmented character, there must be a top pixel whose y
value is the biggest. The x and y coordinate of top pixel of character i is xi and yi,
respectively. Owing to the linearity of the top coordinates, the relationship between x
and y can be expressed as the following formula:

y = a + bx .
By minimizing
Q =

N

 (y
i =1

i

 a  bx

i

)2 ,

We obtain:
x =
L xx =

N



i =1

1
N

N



i =1

1
xi , y =
N

N



i =1
2

N
N
1  N  N 
1 N 

1  N
2
  x i  , L yy =  yi    yi  , Lxy =  xi yi    xi   yi  .
N  i =1  i =1 
N  i =1 
N  i =1 
i =1
i =1
2

x i2 

yi ,

The coefficient a, b and fitting coefficient

b=

Lxy
Lxx

,



a = y  bx ,  =

are as follows:

Lxy
Lxx Lyy

=b

Lxx
.
Lyy

And the top tilting degree is arctan b . By the same token, the bottom tilting degree can be calculated. If the top tilting degree and the bottom tilting degree are all
positive or negative, the plate is deemed to be tilted. The tilting degree is the average
of top tilting degree and bottom tilting degree weighed by top fitting coefficient and
bottom fitting coefficient respectively. In the case of Figure 10, the top tilting degree
and bottom tilting degree is 2.46 and 1.82, respectively. The fitting coefficients are
both 1.00. So its tilting degree is:

( 2.46 ) ( 1.00) + ( 1.82) ( 1.00) = 2.14 .
( 1.00  1.00)
It's more than 2, so rotation is needed.

Fig. 14. Plate after tilt correction

The rotation is performed by the following formula:

g ( x, y ) = f ( x cos + y  sin  + x0 , x sin  + y  cos + y0 ) = f ( x, y ) ,
x = x cos + y  sin  + x0 ,
y =  x sin  + y  cos + y0 .

Automatic License Plate Recognition System Based on Color Image Processing

1167

where x' and y' are the coordinates of the new and x and y are those of the old,  the
rotation degree and

(x0 , y0 ) the rotation center. But in most cases x0 or y0 is not

integer, so linear interpolation is employed and the result is shown in Fig. 14 and 15.

Fig. 15. Segmented characters of Figure 14 (before other optimizations)

3.3 Character Recognition
If the WHR of the character is less than 1/3, it is tried to be recognized as '1'.
For '1' candidates, if its pixel fill rate is more than 0.6, it is recognized as '1', otherwise discarded.
For other characters, first, its size is normalized to 32X64. Then, minimum Euclidean distance based template matching is used to recognize each character [2][3]. And
for those confusing characters such as '8' & 'B' and '0' & 'D', a special processing is
necessary. Pixels do differ in the left top triangle and in the left bottom triangle of
these 4 characters. This property endows us the opportunity to distinguish '8' from 'B'
or '0' from 'D' by checking these two triangles. Also, in China mainland, the second
character is alphabetic, the third and fourth character is alphanumeric and the last
three is numeric, this can constrain the matching in the alphanumeric template set and
eliminate the unnecessary incorrect recognition from letter to digit or vice versa.
3.4 Validity Checking
Validity is checked by machine and manual. For machine, the plate is searched in
database to see whether it indeed exists. If the matched record does exist and is retrieved, the color of background and foreground of the plate is compared to those in it.
If either of the former conditions fails, the vehicle will be stopped. And if the plate is
on the blacklist, say, wanted by the police, it should be detained either. For manual,
the type (oversize or light-duty), the brand (Benz or BMW) and the color of the current car body are compared to the information in the database. Again, if it fails, the
vehicle will be held.

4 Conclusion
The experiment performed by program based on aforesaid algorithms indicates that
our LPR system based on color image processing is quite quick and accurate. Even
on a PIII 1G PC, 90% of the photos under various illuminations are read correctly
within 0.3s.
In this article, the automatic Chinese LPR system based on color image processing
is proposed. The using of color image processing instead of grayscale, the further
division from 6 colors to 13 colors to gain the robustness under various illuminations
and the selection of channel are the major breakthroughs. And there are also some
empirical rules, such as the computation of threshold value, the optimizations during

1168

X. Shi, W. Zhao, and Y. Shen

character segmentation and the special processing to distinguish '8' from 'B' or '0'
from 'D'. The end justifies the means. Last but not least, the validity check is performed. It is of absolute necessity to be introduced into a practical LPR system.

References
1. D.H. Ballard, Computer vision. Prentice-Hall Inc., (1991)
2. Ahmed, M. J., Sarfraz, M., Zidouri, A., and Alkhatib, W. G., License Plate Recognition
System, The Proceedings of The 10th IEEE International Conference On Electronics, Circuits And Systems (ICECS2003), Sharjah, United Arab Emirates (UAE).
3. Sarfraz, M., Ahmed, M., and Ghazi, S. A. (2003), Saudi Arabian License Plate Recognition System, The Proceedings of IEEE International Conference on Geoemetric Modeling
and Graphics-GMAG2003, London, UK, IEEE Computer Society Press.
4. Shyang-Lih Chang, Li-Shien Chen, Yun-Chung Chung, Sei-Wan Chen, Automatic license
plate recognition, IEEE Transactions on Intelligent Transportation Systems, Vol.: 5, Issue:
1, (2004) 42-53
5. Guangzhi Cao, Jianqian Chen, Jingping Jiang, An adaptive approach to vehicle license
plate localization, IECON '03. The 29th Annual Conference of the IEEE Industrial Electronics Society, Vol.: 2 (2003) 1786-1791
6. K. Lanayama, Y. Fujikawa, K. Fujimoto, M. Horino, Development of Vehicle License
Number Recognition System Using Real-time, Image Processing and its Application to
Travel-Time Measurement. Proceedings of the 41st IEEE Vehicular Technology Conference (1991) 798-804
7. K. M. Kim, B. J. Lee, K. Lyou, G. T. Park. The automatic Recognition of the Plate of Vehicle Using the Correlation Coefficient and Hough Transform, Journal of Control, Automation and Systems Engineering, Vol.3, No.5, (1997) 511-519
8. M. Shridhar, J. W. Miller, G. Houle, L. Bijnagte, Recognition of License Plate Images: Issues and Perspectives. Proceedings of International Conference on Document Analysis and
Recognition, (1999) 17-20
9. Sunghoon Kim, Daechul Kim, Younbok Ryu, Gyeonghwan Kim, A Robust License-plate
Extraction Method under Complex Image Conditions, Proceedings. 16th International
Conference on Pattern Recognition, (ICPR'02) Vol. 3 (2002) 216-219
10. H. J. Choi, A Study on the Extraction and Recognition of a Car Number Plate by Image
Processing, Journal of Korea Institute of Telematics and Electronics(KITE) (1987) Vol. 24
No. 2, 309-315
11. B. T. Cheon et al, The Extraction of a Number Plate from a Moving car, Proc. of First
Workshop on Character Recognition (1993) 133-136
12. H. S. Chong and H. J. Cho, Locating Car License Plate Using Subregion Features, Journal
of the KISS (1994) Vol. 21 No. 6, 1149-1159
13. Prewitt, J.M.S. and Mendelsohn, M.L. The analysis of cell images, in Ann. N.Y. Acad.
Sci, (1966) 1035-1053
14. E. R. Lee, P. K. Kim, H. J. Kim, Automatic Recognition of a Car License Plate Using
Color Image Processing, IEEE International Conference on Image Processing, Vol. 2,
(1994) 301-305

