Accepted Manuscript

Gaussian process classification for prediction of in-hospital mortality
among preterm infants
Olli-Pekka Rinta-Koski, Simo Sarkka, Jaakko Hollmen,
Markus Leskinen, Sture Andersson
PII:
DOI:
Reference:

S0925-2312(18)30208-X
10.1016/j.neucom.2017.12.064
NEUCOM 19352

To appear in:

Neurocomputing

Received date:
Revised date:
Accepted date:

4 July 2017
10 November 2017
21 December 2017

Please cite this article as: Olli-Pekka Rinta-Koski, Simo Sarkka, Jaakko Hollmen, Markus Leskinen,
Sture Andersson, Gaussian process classification for prediction of in-hospital mortality among preterm
infants, Neurocomputing (2018), doi: 10.1016/j.neucom.2017.12.064

This is a PDF file of an unedited manuscript that has been accepted for publication. As a service
to our customers we are providing this early version of the manuscript. The manuscript will undergo
copyediting, typesetting, and review of the resulting proof before it is published in its final form. Please
note that during the production process errors may be discovered which could affect the content, and
all legal disclaimers that apply to the journal pertain.

ACCEPTED MANUSCRIPT

Gaussian process classification for prediction of
in-hospital mortality among preterm infants

CR
IP
T

Olli-Pekka Rinta-Koskia,, Simo Sarkkab , Jaakko Hollmena , Markus Leskinenc ,
Sture Anderssonc
a Aalto

AN
US

University, Department of Computer Science, PO Box 15400, FI-00076 Aalto,
Finland
b Aalto University, Department of Electrical Engineering and Automation, PO Box 12200,
FI-00076 Aalto, Finland
c University of Helsinki, and Helsinki University Hospital, PO Box 140, FI-00029 HUS,
Finland

Abstract

We present a method for predicting preterm infant in-hospital mortality using
Bayesian Gaussian process classification. We combined features extracted from
sensor measurements, made during the first 72 hours of care for 598 Very Low

M

Birth Weight infants of birth weight <1500 g, with standard clinical features
calculated on arrival at the Neonatal Intensive Care Unit. Time periods of 12,
18, 24, 36, 48, and 72 hours were evaluated. We achieved a classification result

ED

with area under the receiver operating characteristic curve of 0.948, which is
in excess of the results achieved by using the clinical standard SNAP-II and
SNAPPE-II scores.

PT

Keywords: time series prediction; Gaussian process classification; very low

CE

birth weight infants; neonatal intensive care

1. Introduction

AC

This article is related to the use of data-driven methods in the context of dig-

ital healthcare and health informatics [1, 2]. In particular, our aim is to develop
 Corresponding

author
Email addresses: olli-pekka.rinta-koski@aalto.fi (Olli-Pekka Rinta-Koski),
simo.sarkka@aalto.fi (Simo Sarkka), jaakko.hollmen@aalto.fi (Jaakko Hollmen),
markus.leskinen@hus.fi (Markus Leskinen), sture.andersson@hus.fi (Sture Andersson)

Preprint submitted to Neurocomputing

February 21, 2018

ACCEPTED MANUSCRIPT

machine learning methodology for integration of heterogeneous data sources in
5

order to more accurately predict the survival chances of preterm infants during
treatment in the Neonatal Intensive Care Unit (NICU). First, we combine the

CR
IP
T

conventional scoring system used in clinical practice with data-driven prediction
from raw sensor data. Second, we study the prediction accuracy when the clini-

cal scores are completely replaced with measurement data. The development of
10

new methods for predicting neonatal in-hospital mortality is important, because
while the global under-five mortality rate has dropped 53% since 1990, the proportion of neonatal deaths is projected to increase from 45% in 2015 to 52% by

AN
US

2030 [3]. The incidence of certain complications (e.g. necrotizing enterocolitis)
increases with the survival of preterm infants who previously would have died
15

before the onset of these problems, emphasizing the need for developing new
methods and strategies for neonatal intensive care [4]. Furthermore, data-only
prediction is extremely important in clinical work, because the determination
of the conventional scores is labor-intensive and requires that a specific set of

M

diagnostic markers is available.

Routinely available markers of risk  sex, birth weight, and gestational age 

20

ED

fail to predict observed variation of mortality in NICUs [5]. This has prompted
development of illness severity scores, such as SNAP-II and SNAPPE-II [6],
which add laboratory results and physiological measurements of vital signs to

25

PT

perinatal risk factors in order to better predict morbidity and mortality. These
risk scores were developed when patient records were mostly collected by hand,

CE

relying on simplified presentation of physiological data such as lowest temperature and mean blood pressure. Current patient information systems and patient
monitors have made collection of detailed medical data much easier. We hy-

AC

pothesized that time series data of vital signs would help to identify patients at

30

risk and, when combined with traditional risk scores, would result in increased
predictive power.
The machine learning methodology that we use is based on the use of Gaus-

sian process (GP) classification [7] with features extracted from raw cardiac,
arterial and oximeter sensor measurements in addition to the clinical scores,
2

ACCEPTED MANUSCRIPT

35

gestational age at birth, and birth weight. Our motivation for studying GP
classifiers in this context stems from two properties of GPs. First, they are genuine probabilistic models [7] and can provide information on how certain we are

CR
IP
T

about the answer. This feature is inherent in GPs whereas, for example, for support vector machines (SVMs) [8] the uncertainty needs to be estimated with an
40

additional model on the basic SVM [9]. Second, an even more important prop-

erty is that GPs can flexibly be combined with first principles models [10, 11].
The resulting latent force models (LFMs) have a huge potential in medical applications especially due to their connection with time-series models used in sensor

45

AN
US

signal processing [12, 13, 14]. As shown in these papers, it is even possible to

see that GPs models are solutions to certain stochastic partial differential equations, which not only allow for the combination with first-principles physical
models, but also enable the use of Kalman filtering and other Bayesian filtering
methods [15] for computationally efficient implementation of GP classifiers. GP
classifiers have been previously used in health data analysis in (adult) Intensive
Care Units (ICU) [16, 17, 18] and machine learning methods have been applied
to NICU data [19, 20].

M

50

ED

The contribution of this paper is that using cross-validation we show that
augmenting the staff-determined SNAP-II and SNAPPE-II scores with sensor
measurements improves prediction accuracy over standard clinical measures.
We also show that a data-driven prediction from measurements alone can lead

PT

55

to better prediction accuracy than SNAP-II and SNAPPE-II. The proposed

CE

approach gives the area under the receiver operating characteristic curve (AUC)
0.946 for mortality prediction, which compares favourably with AUC 0.9151
reported for logistic regression by Saria et al. [20], and AUC 0.913 for CRIBII and AUC 0.907 for SNAPPE-II reported by Reid et al. [21]. Although it

AC

60

has previously been shown [6] that in-hospital mortality of preterm infants is
strongly correlated with birth weight and gestational age at birth, we show that
the prediction result achieved by using these two variables alone (Table 2) can
be improved by adding features extracted from measurement time series.

65

This article is an extended version of the conference article Prediction of
3

ACCEPTED MANUSCRIPT

preterm infant mortality with Gaussian process classification [22] presented
at the 25th European Symposium on Articial Neural Networks, Computational
Intelligence and Machine Learning (ESANN 2017), in which we looked at data

70

CR
IP
T

from the first postnatal 24 hours. Here the analysis has been extended to six
different time periods ranging between the first 12 and 72 postnatal hours, three
different kernels have been used with the GP classifier, and the classification
performance has been compared to other classifiers.

2. Materials and methods

AN
US

2.1. NICU database

The NICU at Helsinki University Hospital has been collecting patient data

75

in a database since 1999. Data include measurements of clinical parameters
such as oxygen saturation by pulse oximetry (SpO2 ) and supplemental oxygen
levels, observations made by staff, and clinical outcomes. Our study cohort

80

M

includes 2059 Very Low Birth Weight (VLBW) infants (birth weight <1500 g)
admitted between 19992013. Median gestational age at birth was 202 days

ED

(H28+6 weeks) and median birth weight was 1102 g.
The NICU database contains data recorded from equipment interfaces, as
well as notations made by hand. Automatically gathered data consists of 111

85

PT

different variables taken from monitor outputs of equipment used in the NICU.
As the monitoring equipment and clinical guidelines have varied during the 15
year period under which the data has been stored, not all data is available for

CE

all 2059 patients.

AC

2.2. Preprocessing and feature extraction

90

For the experiment, we decided to study the first 72 hours from delivery

to see whether the time series data gathered during that period has predictive
power. Most in-hospital deaths occur within the first week; median in this
dataset is 5 days. There are 598 patients in the dataset for whom there is
complete data from the first 72 hours of their NICU stay for each of these seven

4

ACCEPTED MANUSCRIPT

variables: gestational age at birth, birth weight, systolic, mean, and diastolic
95

arterial blood pressure, heart rate measured by electrocardiography (ECG), and
SpO2 . If for some sensor signal there were only a few measurements available,

CR
IP
T

the patient data was considered incomplete. Patients that died before the end
of 72 hour period were excluded as well. The in-hospital mortality rate of this

subset is 9% (53 patients), which is also the mortality rate in the full cohort.
100

In addition to the full 72 hour period, we also looked at the first 12, 18, 24, 36,
and 48 hour periods.

The data was preprocessed by removing out-of-range values caused by, for

of calibration from the time series.

AN
US

example, misplaced or removed sensors and monitoring equipment drifting out

For feature extraction, mean and standard deviation were calculated from

105

each of the following time series for each patient: systolic, mean, and arterial blood pressure, ECG heart rate, and SpO2 . SNAP-II score, SNAPPE-II
score, gestational age at birth, and birth weight were directly used as features.

110

M

We chose not to use any more complicated features such as signal derivatives,
because the signals streams were very sparse and noisy, and reliably estimat-

ED

ing the signal derivatives would have required us to use Kalman filter type
of methods [15], which we wanted to avoid at this stage in order to keep the

PT

preprocessing simple and robust.
2.3. Gaussian process classifier
We used a GP [7] classifier with a probit measurement model:
Z yi f (xi )
f (x)  GP(0, k(x, x0 )) p(yi | f (xi )) =
N(z | 0, 1) dz

CE

115

(1)



where the classes are labeled as yi  {1, 1}. This choice of the measurement

AC

model is standard in GP literature [7] and is supported by most GP software
packages such as the GPstuff Toolbox [23].

120

The kernel was a sum of squared exponential (or radial basis function) kernel,

linear kernel, and constant kernel:


1
2
k(x, x0 ) = se
exp  (x  x0 )T 1 (x  x0 ) + xT  x0 +  2 ,
2
5

(2)

ACCEPTED MANUSCRIPT

where  = diag(l12 , . . . , ld2 ) and  = diag(12 , . . . , d2 ). The rationale behind
this kernel choice is that the constant and the linear parts of the kernel aim at
capturing the bias and the linear trend in the problem, respectively. In order

125

CR
IP
T

to capture the non-linear effects, we add the squared exponential kernel with
the automatic relevance determination prior, which is a commonly used general
covariance function in Gaussian process regression [7]. This kind of 3-part co-

variance functions have also been recently used in medical applications [24, 25].
For comparison purposes, we also used the Matern kernel with  = 3/2

130

kernel in the 3-part kernel:

AN
US

(M32) and  = 5/2 (M52) [7, 23, 24, 25] replacing the squared exponential

2
k=3/2 (x, x0 ) = m
(1 +
2
k=5/2 (x, x0 ) = m
(1 +






3kx  x0 k) exp( 3kx  x0 k)

5kx  x0 k +


5kx  x0 k2
) exp( 5kx  x0 k)
3

(3)
(4)

For training the classifier we used the GPstuff Toolbox [23] with Laplace

M

approximation on the latent variables and circular composite design (CCD) integration over the hyperparameters. The CCD method has advantages over, for
135

example, marginal likelihood maximization due it better handling of uncertainty.

ED

In particular, the method approximates the integration over the hyperparameters instead of using a plug-in point-estimate, which ensures that the uncertainly

PT

is computed in a proper Bayesian way.
In order to evaluate the performance of the classifiers we used stratified 8-fold
140

cross-validation (CV) which takes the class priors into account when forming

CE

the partitions. Cross-validation was used to estimate the classification accuracy,
precision, specificity, and sensitivity as well as receiver operating characteristic
(ROC) curve [26] and the area under the ROC curve (AUC) [27]. In order to

AC

reduce the variance of CV, we repeated each CV run 8 times and averaged the

145

results.
2.4. Comparison with other classifiers
We used the following classifiers in comparison with the GP classifier:

6

ACCEPTED MANUSCRIPT

 SNAP-II/SNAPPE-II thresholding. Thresholding using only the SNAPII or SNAPPE-II scores (one at a time) was used to classify the patients.
The class boundary was set using one of two rules. In the first case, the

150

CR
IP
T

maximum accuracy achieved with the training set was used to set the
class boundary. In the second case, the maximum value of the Youden
index [28] was used. This gave us four different rule-score combinations.

 Support vector machine classifier. A linear SVM classifier [8] was used as
the classifier and the posterior probability estimates were obtained with

155

Platt scaling [9]. The ROC curve was calculated by sweeping the class

AN
US

boundary from 0 to 1. The prediction was given by setting the class
boundary to 0.5.

 Linear probit model. A linear model with a probit link function was implemented by using a constant plus a linear kernel in a GP classification

160

model. The model was trained using the GPstuff Toolbox. The integration

M

over the hyperparameters was performed using the CCD method [29].
 Random classifier. This classifier assigns the class at random weighted by

ED

class prior probabilities of the training set.
 Majority classifier. This classifier simply assumes that all patients belong

165

PT

to the larger (survivor) class.

CE

3. Results

3.1. Classification with SNAP-II and SNAPPE-II scores
First, we tested the performance of the classifiers using only SNAP-II and

SNAPPE-II scores with gestational age at birth and birth weight. Although

AC

170

this information is equal to what the scores are traditionally computed from,
as can be seen in Tables 1 and 2, the GP classifier is able to achieve a better
AUC (0.933) than the clinical standard SNAP-II (AUC 0.860) and SNAPPE-II
(AUC 0.878) scores, with all variants (sum, M32, M52) giving practically the

175

same result and linear probit classifier at a just slightly lower AUC (0.921).
7

ACCEPTED MANUSCRIPT

Table 1: Reference results.

0.914
0.737
0.909
0.713
0.839
0.910

PPV

(0.00)
(0.01)
(0.00)
(0.01)
(0.01)
(0.00)

0.898
0.248
0.677
0.227
0.091
1.000

Sens

(0.05)
(0.01)
(0.08)
(0.01)
(0.02)
(0.00)

0.056
0.923
0.062
0.895
0.091
0.000

Spec

(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.00)

0.998
0.719
0.993
0.695
0.913
1.000

AUC

(0.00)
(0.01)
(0.00)
(0.01)
(0.01)
(0.00)

0.875
0.875
0.859
0.859
0.500
0.500

(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)

CR
IP
T

Acc
SNAPPE A
SNAPPE Y
SNAP A
SNAP Y
Random
Majority

SNAP/SNAPPE = SNAP-II/SNAPPE-II with optimal (cross-validated) thresh-

olding (A = maximal accuracy, Y = Youden index), Majority = trivial classifier
that assumes all patients survive, Random = class picked at random weighted by

AN
US

training set class priors. Acc = accuracy, PPV = positive predictive value, Sens =

sensitivity, Spec = specificity, AUC = area under the receiver operating characteristic curve. Values in parentheses indicate the associated standard error. Results
in all tables in descending order by AUC.

Table 2: Results using only SNAP-II, SNAPPE-II, gestational age at birth, and birth weight.

(0.00)
(0.00)
(0.00)
(0.00)
(0.00)

PPV

0.611
0.618
0.615
0.579
0.857

(0.04)
(0.05)
(0.04)
(0.05)
(0.06)

ED

0.918
0.919
0.919
0.914
0.907

Sens

0.360
0.351
0.358
0.260
0.020

M

Acc

GP M32
GP
GP M52
Linear
SVM

(0.03)
(0.03)
(0.03)
(0.03)
(0.01)

Spec

0.974
0.975
0.974
0.978
0.994

(0.00)
(0.00)
(0.00)
(0.00)
(0.00)

AUC

0.933
0.933
0.933
0.921
0.644

(0.00)
(0.00)
(0.00)
(0.00)
(0.01)

Next, we used all available signals with the GP classifier in order to get an

PT

upper bound on the achievable performance. All the available features were
used as classifier inputs, in other words, SNAP-II, SNAPPE-II, gestational age

CE

at birth, birth weight, and the mean and standard deviation of each of the
180

following: systolic, mean, and diastolic arterial blood pressure, ECG heart rate,

AC

and SpO2 .

Table 3 (all available features) shows GP prediction results using all available

features with three different kernels (sum, M32, and M52). Kernel choice had
a negligible effect. The highest AUC (0.948) was achieved with 48h data and

185

the sum kernel. All AUC values from predictions with all three kernels for time
periods between 36h and 72h were within 0.007. Shortening the range of time

8

ACCEPTED MANUSCRIPT

series data has a slight negative effect on the AUC values, with 12h data and the
sum kernel yielding AUC 0.924. However, as the range decreases, there is a drop
in both positive predictive value (PPV), from 0.708 to 0.598, and sensitivity,
from 0.463 to 0.283. SVM and the linear probit model give similar results to GP

CR
IP
T

190

(Tables 4 and 5) in many of the cases, but with shorter ranges the GP models
give slightly better results.

Table 3: GP prediction results using all available features and three different kernels (sum,
M32, M52).

PPV
0.660
0.649
0.657
0.667
0.708
0.717
0.669
0.727
0.670
0.591
0.596
0.671
0.624
0.655
0.682
0.598
0.590
0.581

Sens

(0.03)
(0.03)
(0.03)
(0.03)
(0.03)
(0.03)
(0.03)
(0.03)
(0.03)
(0.04)
(0.04)
(0.03)
(0.03)
(0.04)
(0.03)
(0.04)
(0.04)
(0.03)

M

(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)

ED

0.930
0.928
0.928
0.925
0.932
0.933
0.925
0.934
0.924
0.918
0.919
0.920
0.919
0.920
0.922
0.915
0.913
0.913

PT

GP
GPm32
GPm52
GPm32
GP
GPm52
GPm52
GPm32
GP
GPm32
GPm52
GPm32
GP
GP
GPm52
GP
GPm32
GPm52

0.463
0.445
0.442
0.391
0.449
0.453
0.390
0.452
0.389
0.332
0.331
0.312
0.335
0.328
0.335
0.283
0.295
0.297

(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.03)
(0.03)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)

Spec

0.975
0.975
0.976
0.977
0.980
0.980
0.977
0.981
0.977
0.976
0.977
0.981
0.976
0.979
0.980
0.977
0.974
0.974

(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)

AN
US

Acc
48h
48h
48h
36h
72h
72h
36h
72h
36h
24h
24h
18h
24h
18h
18h
12h
12h
12h

AUC

0.948
0.947
0.946
0.945
0.942
0.942
0.942
0.942
0.941
0.931
0.930
0.929
0.929
0.928
0.928
0.924
0.923
0.921

(0.00)
(0.00)
(0.00)
(0.00)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.00)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)

CE

Finally, Table 6 shows the results for all non-reference classifiers using all
available features. GP kernel choice had negligible effect. The linear probit
model performs worse than GP with 12h and 18h data. With longer time
series, GP and the linear probit model have roughly equal performance. Even

AC

195

the lowest AUC (0.901), given by the SVM classifier with 12h data, is better
than SNAP-II/SNAPPE-II thresholding (AUC 0.859. . . 0.875).

9

ACCEPTED MANUSCRIPT

Table 4: SVM prediction results using all available features.

36h
48h
24h
72h
18h
12h

0.931
0.931
0.923
0.931
0.918
0.910

(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)

PPV

0.708
0.725
0.665
0.746
0.692
0.564

(0.03)
(0.03)
(0.03)
(0.03)
(0.04)
(0.04)

Sens

0.443
0.433
0.340
0.384
0.259
0.182

(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)

Spec

0.979
0.980
0.981
0.984
0.984
0.982

(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)

AUC

0.947
0.943
0.930
0.924
0.922
0.901

(0.00)
(0.00)
(0.01)
(0.01)
(0.00)
(0.01)

CR
IP
T

Acc

Table 5: Linear model prediction results using all available features.

0.926
0.924
0.934
0.919
0.922
0.913

(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)

PPV

0.645
0.652
0.720
0.610
0.675
0.583

(0.02)
(0.03)
(0.03)
(0.04)
(0.04)
(0.04)

Sens

0.463
0.402
0.475
0.348
0.326
0.279

(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)

Spec

0.971
0.975
0.979
0.976
0.981
0.976

(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)

AUC

0.949
0.949
0.944
0.931
0.927
0.916

AN
US

Acc

48h
36h
72h
24h
18h
12h

(0.00)
(0.00)
(0.00)
(0.01)
(0.01)
(0.01)

3.2. Classification with reduced feature sets

To find out how the classifiers perform with reduced feature sets, we tested

M

200

the classifiers without SNAP-II and SNAPPE-II scores (Table 7) and finally

Table 8).

ED

with sensor signals only (dropping also gestational age at birth and birth weight,

Without SNAP-II/SNAPPE-II, the linear probit model and GP perform
equally well with time periods of at least 36h (AUC 0.943. . . 0.946). All classifiers

PT

205

outperform the reference results (Table 1), with the exception of SVM with
12h data (AUC 0.874) which achieves a result comparable with SNAPPE-II

CE

thresholding.

Table 8 shows prediction results using only time series data. The best classi-

210

fier is GP (all kernels) with 48h data (AUC 0.925. . . 0.926) but linear classifiers

AC

with 48h and 72h data as well as GP with 72h data perform almost equally
well. Whereas the GP kernel choice is again practically immaterial, both AUC
and sensitivity increase as the time series grows longer, AUC from 0.787 (12h
data, M32 kernel) to 0.926 (48h data, sum kernel). Interestingly, 72h data gives

215

slightly lower AUC values than 48h data (AUC 0.915. . . 0.919 vs. 0.925. . . 0.926),

10

ACCEPTED MANUSCRIPT

Table 6: Prediction results using all available features. Comparison of GP, SVM, and linear

Sens

(0.02)
(0.03)
(0.03)
(0.03)
(0.03)
(0.03)
(0.03)
(0.03)
(0.03)
(0.03)
(0.03)
(0.03)
(0.03)
(0.03)
(0.04)
(0.04)
(0.03)
(0.04)
(0.03)
(0.03)
(0.04)
(0.03)
(0.04)
(0.03)
(0.04)
(0.04)
(0.04)
(0.03)
(0.04)
(0.04)

0.463
0.402
0.463
0.443
0.445
0.442
0.391
0.475
0.433
0.449
0.453
0.390
0.452
0.389
0.332
0.348
0.340
0.331
0.312
0.335
0.328
0.335
0.326
0.384
0.283
0.295
0.259
0.297
0.279
0.182

(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.03)
(0.02)
(0.02)
(0.03)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)

Spec
0.971
0.975
0.975
0.979
0.975
0.976
0.977
0.979
0.980
0.980
0.980
0.977
0.981
0.977
0.976
0.976
0.981
0.977
0.981
0.976
0.979
0.980
0.981
0.984
0.977
0.974
0.984
0.974
0.976
0.982

(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)

AUC
0.949
0.949
0.948
0.947
0.947
0.946
0.945
0.944
0.943
0.942
0.942
0.942
0.942
0.941
0.931
0.931
0.930
0.930
0.929
0.929
0.928
0.928
0.927
0.924
0.924
0.923
0.922
0.921
0.916
0.901

(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.00)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.00)
(0.01)
(0.01)
(0.01)

CR
IP
T

PPV
0.645
0.652
0.660
0.708
0.649
0.657
0.667
0.720
0.725
0.708
0.717
0.669
0.727
0.670
0.591
0.610
0.665
0.596
0.671
0.624
0.655
0.682
0.675
0.746
0.598
0.590
0.692
0.581
0.583
0.564

M

(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)

AN
US

Acc
0.926
0.924
0.930
0.931
0.928
0.928
0.925
0.934
0.931
0.932
0.933
0.925
0.934
0.924
0.918
0.919
0.923
0.919
0.920
0.919
0.920
0.922
0.922
0.931
0.915
0.913
0.918
0.913
0.913
0.910

PT

Linear
Linear
GP
SVM
GPm32
GPm52
GPm32
Linear
SVM
GP
GPm52
GPm52
GPm32
GP
GPm32
Linear
SVM
GPm52
GPm32
GP
GP
GPm52
Linear
SVM
GP
GPm32
SVM
GPm52
Linear
SVM

CE

48h
36h
48h
36h
48h
48h
36h
72h
48h
72h
72h
36h
72h
36h
24h
24h
24h
24h
18h
24h
18h
18h
18h
72h
12h
12h
18h
12h
12h
12h

ED

probit model.

but with better PPV and sensitivity (PPV 0.804. . . 0.813 vs. 0.639. . . 0.645, sen-

AC

sitivity 0.347. . . 0.361 vs. 0.320. . . 0.335). Time periods shorter than 36h do not
give better than reference results with any of the classifiers.

220

The best SVM result (AUC 0.899, 48h data) equals the performance of GP

and linear classifiers with 36h data, but loses to both with time periods of 48h
and 72h. SVM performance degrades markedly with 24h and shorter data, not

11

ACCEPTED MANUSCRIPT

beating even the reference (SNAP-II/SNAPPE-II) classifiers.
Table 7: Prediction results using all available features except SNAP-II and SNAPPE-II.

CE

Sens

(0.03)
(0.03)
(0.03)
(0.03)
(0.02)
(0.03)
(0.03)
(0.03)
(0.02)
(0.03)
(0.02)
(0.03)
(0.03)
(0.03)
(0.03)
(0.03)
(0.03)
(0.04)
(0.03)
(0.03)
(0.03)
(0.03)
(0.03)
(0.03)
(0.04)
(0.04)
(0.04)
(0.03)
(0.04)
(0.05)

0.442
0.464
0.445
0.433
0.445
0.400
0.403
0.412
0.503
0.457
0.448
0.439
0.413
0.413
0.396
0.357
0.349
0.343
0.328
0.333
0.345
0.405
0.337
0.306
0.258
0.253
0.253
0.259
0.256
0.084

(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.03)
(0.03)
(0.03)
(0.03)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.01)

Spec

0.976
0.971
0.976
0.975
0.981
0.973
0.973
0.973
0.976
0.973
0.980
0.980
0.978
0.981
0.976
0.977
0.975
0.975
0.980
0.980
0.981
0.984
0.979
0.985
0.979
0.979
0.977
0.987
0.981
0.990

(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)

AUC

0.947
0.947
0.946
0.946
0.946
0.945
0.945
0.945
0.945
0.945
0.944
0.943
0.941
0.941
0.931
0.930
0.930
0.930
0.925
0.925
0.924
0.923
0.920
0.919
0.914
0.913
0.912
0.907
0.900
0.874

(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.01)
(0.01)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)

CR
IP
T

PPV

0.680
0.655
0.678
0.668
0.735
0.634
0.617
0.627
0.705
0.655
0.723
0.713
0.691
0.699
0.639
0.608
0.590
0.570
0.674
0.670
0.678
0.742
0.659
0.733
0.586
0.591
0.562
0.738
0.594
0.622

M

(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)

ED

0.928
0.926
0.929
0.926
0.934
0.922
0.922
0.923
0.934
0.927
0.933
0.932
0.927
0.930
0.924
0.921
0.919
0.918
0.921
0.921
0.923
0.932
0.921
0.924
0.914
0.913
0.912
0.921
0.915
0.909

PT

GPm32
Linear
GP
GPm52
GPm32
GP
GPm52
GPm32
Linear
Linear
GPm52
GP
SVM
SVM
Linear
GP
GPm52
GPm32
GPm52
GPm32
GP
SVM
Linear
SVM
GPm32
GPm52
GP
SVM
Linear
SVM

AN
US

Acc

48h
48h
48h
48h
72h
36h
36h
36h
72h
36h
72h
72h
48h
36h
24h
24h
24h
24h
18h
18h
18h
72h
18h
24h
12h
12h
12h
18h
12h
12h

AC

3.3. The effect of varying input combinations and time series lengths

225

Figure 1 shows the ROC curves for classifier results using all features, with-

out SNAP-II/SNAPPE-II, and time series data only for the two extremes (12h,
72h) of time series lengths. The classification performance is improved with
longer time series in all three cases.

12

ACCEPTED MANUSCRIPT

Table 8: Prediction results using only time series data.

Sens

(0.03)
(0.04)
(0.04)
(0.03)
(0.03)
(0.04)
(0.03)
(0.03)
(0.04)
(0.04)
(0.04)
(0.04)
(0.04)
(0.03)
(0.03)
(0.05)
(0.05)
(0.04)
(0.05)
(0.04)
(0.04)
(0.04)
(0.04)
(0.05)
(0.04)
(0.05)
(0.05)
(0.05)
(0.02)
(0.03)

0.335
0.322
0.320
0.347
0.361
0.315
0.352
0.360
0.261
0.259
0.266
0.261
0.272
0.287
0.213
0.194
0.194
0.208
0.186
0.191
0.181
0.186
0.145
0.101
0.089
0.102
0.101
0.076
0.000
0.012

(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.02)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.00)
(0.01)

Spec

0.981
0.981
0.982
0.989
0.989
0.982
0.989
0.988
0.986
0.987
0.988
0.986
0.987
0.994
0.995
0.990
0.989
0.989
0.989
0.994
0.994
0.994
0.991
0.994
0.994
0.993
0.993
0.992
0.999
0.999

(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)

AUC
0.926
0.925
0.925
0.919
0.917
0.917
0.915
0.913
0.902
0.902
0.900
0.899
0.898
0.892
0.881
0.868
0.864
0.857
0.857
0.846
0.845
0.844
0.831
0.799
0.793
0.791
0.787
0.779
0.669
0.597

(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.01)
(0.02)
(0.02)

CR
IP
T

PPV

0.640
0.639
0.645
0.813
0.820
0.674
0.804
0.798
0.715
0.716
0.734
0.747
0.740
0.863
0.874
0.701
0.690
0.703
0.665
0.788
0.796
0.789
0.714
0.737
0.798
0.734
0.727
0.701
0.969
0.935

M

(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)
(0.00)

ED

0.923
0.923
0.923
0.932
0.933
0.922
0.932
0.933
0.922
0.922
0.923
0.922
0.923
0.932
0.925
0.918
0.917
0.919
0.917
0.921
0.920
0.921
0.914
0.914
0.912
0.914
0.913
0.910
0.910
0.909

CE

PT

GP
GPm52
GPm32
GPm32
GPm52
Linear
GP
Linear
GPm52
GPm32
GP
SVM
Linear
SVM
SVM
GPm32
GPm52
GP
Linear
GPm52
GPm32
GP
Linear
GP
SVM
GPm52
GPm32
Linear
SVM
SVM

AN
US

Acc

48h
48h
48h
72h
72h
48h
72h
72h
36h
36h
36h
48h
36h
72h
36h
24h
24h
24h
24h
18h
18h
18h
18h
12h
24h
12h
12h
12h
12h
18h

Figure 2 shows the effect of varying the length of the time series. Increasing

time series length improves the prediction result up to 48h for GP and the linear
model. There is no marked difference between the 48h and 72h predictions.

AC
230

SVM performance peaks at 32h.
Using only time series data AUC is initially low, surpassing that of the

SNAP-II/SNAPPE-II combination with 36h and longer time series. The best
AUC was achieved with 48h data. Using the full 72h time series results in

13

ACCEPTED MANUSCRIPT

12h

0.8

0.7

0.7

0.6

0.6

0.5
0.4

GP All
Linear All
GPm32 All
GPm52 All
SVM All
SNAP-II
SNAPPE-II
Random

0.3
0.2
0.1
0

0.2

0.4

0.6

0.8

0

1

0

0.2

0.4

0.6

0.8

1

1 - specificity
72h

AN
US
0.7
0.6

0.5
0.4

Sensitivity

0.6

GP TS+GA+BW
Linear TS+GA+BW
GPm32 TS+GA+BW
GPm52 TS+GA+BW
SVM TS+GA+BW
SNAP-II
SNAPPE-II
Random

0.3
0.2
0.1
0

0.2

0.4

0.6

1 - specificity
12h

1

0.8
0.7
0.6

PT

0.5
0.4
0.3
0.2

CE

0.1

0

0.2

0.4

0.8

GP TS+GA+BW
Linear TS+GA+BW
GPm32 TS+GA+BW
GPm52 TS+GA+BW
SVM TS+GA+BW
SNAP-II
SNAPPE-II
Random

0.1

0

1

0

0.2

0.4

0.6

0.8

1

1 - specificity
72h

1
0.9
0.8
0.7
0.6

GP TS only
Linear TS only
GPm32 TS only
GPm52 TS only
SVM TS only
SNAP-II
SNAPPE-II
Random

0.6

0.4

0.2

ED

0.9

0.8

0.5

0.3

M

Sensitivity

0.1

0.8

0.7

Sensitivity

0.2

0.9

0.8

0

GP All
Linear All
GPm32 All
GPm52 All
SVM All
SNAP-II
SNAPPE-II
Random

1

0.9

0

0.4
0.3

1 - specificity
12h

1

0.5

CR
IP
T

0.9

0.8

Sensitivity

0.9

0

72h

1

Sensitivity

Sensitivity

1

0.5
0.4

GP TS only
Linear TS only
GPm32 TS only
GPm52 TS only
SVM TS only
SNAP-II
SNAPPE-II
Random

0.3
0.2
0.1
1

0

0

1 - specificity

0.2

0.4

0.6

0.8

1

1 - specificity

AC

Figure 1: ROC curves for 12h and 72h classifiers. The ROCs of SNAP-II, SNAPPE-II, and
the random classifier are also shown. Top row: all available features. Middle row: time series
data + GA + BW. Bottom row: time series data only.

235

slightly lower AUC scores. The addition of GA and BW improves the result
with short time series (12h and 18h), but has little effect with 24h and longer
14

ACCEPTED MANUSCRIPT

0.9

0.9

0.85

0.85

0.8

0.8

0.75

0.75

0.7

0.7

GP All
Linear All
SVM All
SNAP-II
SNAPPE-II

0.65

0.6

CR
IP
T

AUC

0.95

AUC

0.95

12

18

24

36

48

GP TS+GA+BW
Linear TS+GA+BW
SVM TS+GA+BW
SNAP-II
SNAPPE-II

0.65

0.6

72

12

18

24

36

Hours

72

0.85

AUC

0.8

0.75

0.7

AN
US

0.9

GP TS only
Linear TS only
SVM TS only
SNAP-II
SNAPPE-II

0.65

12

18

24

36

48

M

0.6

48

Hours

0.95

72

Hours

Figure 2: AUC values for different time series lengths. Top left: all variables. Top right: time

PT

time series.

ED

series data with GA and BW. Bottom: time series data only.

4. Discussion

CE

In another study [30], birth weight alone was found to have AUC 0.74 and
240

gestational age alone had AUC 0.71. Both were inferior to the Clinical Risk
Index for Babies (CRIB) [31], which had AUC 0.82. CRIB-II [32] was also

AC

found to have inferior predictive power at AUC 0.69. A comparison study of
CRIB-II and SNAPPE-II [21] found the two scores performing equally well, with
CRIB-II AUC 0.913 (SE 0.014) and SNAPPE-II AUC 0.907 (SE 0.012), while

245

another comparison study [33] found CRIB (AUC 0.90) and CRIB-II (AUC
0.91) superior to SNAPPE-II (AUC 0.84, which is close to our SNAPPE-II
thresholding result).
15

ACCEPTED MANUSCRIPT

While our best prediction results were achieved using all available variables,
adding SNAP-II and SNAPPE-II to time series data with gestational age at
250

birth and birth weight did not markedly improve the results. This is not sur-

CR
IP
T

prising given that both scores are influenced by GA and BW to a great extent.
Both GP classification and the linear probit model gave practically identical

results with time series of 36h and longer. With time series data only, GP and
the linear probit model lose to SNAP-II/SNAPPE-II thresholding with 12h and
255

18h data, achieve roughly equal performance with 24h data, and beat them with

36h and longer time series, as does SVM. However, SVM performs significantly

AN
US

worse than SNAP-II/SNAPPE-II with 12h to 24h data.

In Figure 2 there is a slight drop in performance when using 72h data instead
of 48h data. Although this may look surprising, it could be explained by the
260

fact that the feature computations did not explicitly take the length of the
time interval into account. It is thus possible that by, for example, limiting the
feature computations to the end of the time series or by taking the length of

M

the time interval otherwise into account could improve the predictions.
The highest sensitivity achieved was 0.475 for the linear probit model using
all variables with 72h data. GP sensitivies varied from 0.283 to 0.453 using all

ED

265

variables, dropping down markedly (0.101. . . 0.361) with only time series data.
It is worth noting that low sensitivities of predictions do not necessarily mean

PT

that the clinical value of the predictions is low. From the clinical viewpoint,
specificity is more important than sensitivity when predicting mortality. If the
clinicians suspect that there is a high risk that the preterm infant will die,

CE

270

this can affect decisions to perform risky operations or start resource-intensive
treatments. These kinds of decisions require careful consideration of the clinical

AC

situation and never rely on a single factor, such as predictive models. The goal
is to have as high specificity as possible to avoid withholding treatment.

275

The prediction of in-hospital death in itself is not something that would be a

major factor in how to treat the patient, but it can be useful in deciding whether
to use some heavy means of care such as complex operations which themselves
can be a risk to the patient. For that reason we have chosen to use data from
16

ACCEPTED MANUSCRIPT

the early phase of the NICU stay. In the early stages the medical personnel
280

have not yet been able to form a complete view of the patients state.

CR
IP
T

5. Conclusions
Time series data from the initial hours of a preterm infants intensive care
unit stay can be used to improve the accuracy of existing methods for predicting
in-hospital death. A Bayesian Gaussian process classifier can be used to create
285

a predictive model. Combining features extracted from time series data with
clinical scores calculated on arrival gives classification results in excess of clinical

AN
US

standards. Using only time series data gives results comparable with existing
clinical standards, given a long enough time series.

As current NICU patient data systems already collect sensory data used
290

in this paper, predictive modeling could be included in the care process to
give physicians advance warning of increased risk of in-hospital death. The

M

model already outperforms existing methods in our retrospective cohort and
with further refinement could prove to be a valuable clinical tool.
Acknowledgement. The authors would like to thank Aki Vehtari for help
in Gaussian process classifier design and implementation, and the Academy of

ED

295

Finland (projects 295505 and 266940) for financial support. We acknowledge

PT

the computational resources provided by the Aalto Science-IT project.

CE

References

[1] N. Byrnes, Can Technology Fix Medicine?, MIT Technology Review (Sep/Oct 2014).

300

AC

[2] D. A. Clifton, K. E. Niehaus, P. Charlton, G. W. Colopy, Health Informatics via Machine Learning for the Clinical Management of Patients:, IMIA
Yearbook 10 (1) (2015) 3843. doi:10.15265/IY-2015-014.

[3] D. You, L. Hug, S. Ejdemyr, J. Beise, Levels and trends in child mortality.
305

Report 2015. Estimates developed by the UN Inter-agency Group for Child
17

ACCEPTED MANUSCRIPT

Mortality Estimation., Tech. rep., United Nations Inter-agency Group for
Child Mortality Estimation (UN IGME), New York, NY (2015).
[4] R. M. Patel, S. Kandefer, M. C. Walsh, E. F. Bell, W. A. Carlo, A. R.

CR
IP
T

Laptook, P. J. Sanchez, S. Shankaran, K. P. Van Meurs, M. B. Ball,
E. C. Hale, N. S. Newman, A. Das, R. D. Higgins, B. J. Stoll, Causes

310

and Timing of Death in Extremely Premature Infants from 2000 through

2011, New England Journal of Medicine 372 (4) (2015) 331340. doi:
10.1056/NEJMoa1403489.

AN
US

[5] D. K. Richardson, J. E. Gray, M. C. McCormick, K. Workman, D. A.

Goldmann, Score for Neonatal Acute Physiology: A physiologic severity

315

index for neonatal intensive care, Pediatrics 91 (3) (1993) 617623.
[6] D. K. Richardson, J. D. Corcoran, G. J. Escobar, S. K. Lee, SNAP-II and
SNAPPE-II: Simplified newborn illness severity and mortality risk scores,
The Journal of Pediatrics 138 (1) (2001) 92100. doi:10.1067/mpd.2001.

M

109608.

320

[7] C. E. Rasmussen, C. K. I. Williams, Gaussian Processes for Machine Learn-

ED

ing, The MIT Press, 2006.

[8] C. Cortes, V. Vapnik, Support-vector networks, Machine learning 20 (3)

325

PT

(1995) 273297.

[9] J. C. Platt, Probabilistic Outputs for Support Vector Machines and Com-

CE

parisons to Regularized Likelihood Methods, in: Advances in Large Margin
Classifiers, MIT Press, 1999, pp. 6174.

AC

[10] M. Alvarez, D. Luengo, N. Lawrence, Latent force models, in: Artificial

330

Intelligence and Statistics, 2009, pp. 916.

[11] M. A. Alvarez, D. Luengo, N. D. Lawrence, Linear Latent Force Models
Using Gaussian Processes, IEEE Transactions on Pattern Analysis and
Machine Intelligence 35 (11) (2013) 26932705. doi:10.1109/TPAMI.2013.
86.
18

ACCEPTED MANUSCRIPT

[12] J. Hartikainen, S. Sarkka, Sequential inference for latent force models, Proceedings of The 27th Conference on Uncertainty in Artificial Intelligence

335

(UAI 2011).

CR
IP
T

[13] J. Hartikainen, M. Seppanen, S. Sarkka, State-space inference for non-linear

latent force models with application to satellite orbit prediction, in: Proceedings of the 29th International Conference on Machine Learning (ICML12), Edinburgh, Scotland, UK, 2012, pp. 903910.

340

[14] S. Sarkka, A. Solin, J. Hartikainen, Spatiotemporal learning via infinite-

AN
US

dimensional Bayesian filtering and smoothing: A look at Gaussian process regression through Kalman filtering, IEEE Signal Processing Magazine
30 (4) (2013) 5161.
345

[15] S. Sarkka, Bayesian Filtering and Smoothing, Cambridge University Press,
2013.

M

[16] G. W. Colopy, M. A. Pimentel, D. A. Clifton, S. J. Roberts, Bayesian Gaussian Processes for Identifying the Deteriorating Patient, in: Proceedings of

ED

the 38th Annual Conference of the IEEE Engineering in Medicine and Biology Society, IEEE, Orlando, FL, USA, 16-20 Aug 2016, pp. 53115314.

350

doi:10.1109/EMBC.2016.7591926.

PT

[17] M. Ghassemi, M. A. Pimentel, T. Naumann, T. Brennan, D. A. Clifton,
P. Szolovits, M. Feng, A multivariate timeseries modeling approach to

CE

severity of illness assessment and forecasting in ICU with sparse, heterogeneous clinical data, in: Proceedings of the 29th AAAI Conference on

355

AC

Artificial Intelligence, Vol. 1, NIH Public Access, Austin, TX, USA, 2015,
pp. 446453.

[18] F. Guiza, J. Ramon, H. Blockeel, Gaussian processes for prediction in in-

360

tensive care, in: Gaussian Processes in Practice Workshop, Bletchley Park,
UK, 2006, pp. 14.

19

ACCEPTED MANUSCRIPT

[19] V. Gangadharan, Automated multi-parameter monitoring of neonates,
PhD thesis, UCL (University College London), London (2013).
[20] S. Saria, A. K. Rajani, J. Gould, D. Koller, A. A. Penn, Integration of

CR
IP
T

Early Physiological Responses Predicts Later Illness Severity in Preterm

Infants, Science Translational Medicine 2 (48) (2010) 48ra6548ra65. doi:

365

10.1126/scitranslmed.3001304.

[21] S. Reid, B. Bajuk, K. Lui, E. A. Sullivan, NSW and ACT Neonatal Intensive Care Units Audit Group, PSN, Comparing CRIB-II and SNAPPE-II

AN
US

as mortality predictors for very preterm infants: Comparing CRIB-II and

SNAPPE-II, Journal of Paediatrics and Child Health 51 (5) (2015) 524528.

370

doi:10.1111/jpc.12742.

[22] O.-P. Rinta-Koski, S. Sarkka, J. Hollmen, M. Leskinen, S. Andersson, Prediction of preterm infant mortality with Gaussian process classification,

M

in: Proceedings of the 25th European Symposium on Artificial Neural
Networks, Computational Intelligence and Machine Learning, Bruges, Bel-

375

ED

gium, 26-28 April 2017, pp. 193198.
[23] J. Vanhatalo, J. Riihimaki, J. Hartikainen, P. Jylanki, V. Tolvanen, A. Vehtari, GPstuff: Bayesian modeling with Gaussian processes, Journal of

380

PT

Machine Learning Research 14 (Apr) (2013) 11751179.
[24] A. Solin, S. Sarkka, The 10th annual MLSP competition: First place, in:

CE

2014 IEEE International Workshop on Machine Learning for Signal Processing (MLSP), IEEE, 2014, pp. 13.

AC

[25] K. Suotsalo, S. Sarkka, Detecting Malignant Ventricular Arrhythmias in

385

Electrocardiograms by Gaussian Process Classification, in: Proceedings of
the 27th IEEE International Workshop on Machine Learning for Signal
Processing (MLSP), IEEE, Tokyo, Japan, September 25-28, 2017.

[26] J. A. Swets, Measuring the Accuracy of Diagnostic Systems, Science 240
(1988) 12851293.
20

ACCEPTED MANUSCRIPT

[27] A. P. Bradley, The use of the area under the ROC curve in the evaluation of
machine learning algorithms, Pattern recognition 30 (7) (1997) 11451159.

390

[28] W. J. Youden, Index for rating diagnostic tests, Cancer 3 (1950) 32

CR
IP
T

35. doi:10.1002/1097-0142(1950)3:1<32::AID-CNCR2820030106>3.0.
CO;2-3.

[29] H. Rue, S. Martino, N. Chopin, Approximate Bayesian inference for latent Gaussian models by using integrated nested Laplace approximations,

395

Journal of the Royal Statistical Society: Series B (Statistical Methodology)

AN
US

71 (2) (2009) 319392. doi:10.1111/j.1467-9868.2008.00700.x.

[30] C. Buhrer, B. Metze, M. Obladen, CRIB, CRIB-II, birth weight or gestational age to assess mortality risk in very low birth weight infants?, Acta
Paediatrica 97 (7) (2008) 899903.

400

00793.x.

doi:10.1111/j.1651-2227.2008.

M

[31] The International Neonatal Network, The CRIB (clinical risk index for
babies) score: A tool for assessing initial neonatal risk and comparing per-

193198.

405

ED

formance of neonatal intensive care units, The Lancet 342 (8865) (1993)

[32] G. Parry, J. Tucker, W. Tarnow-Mordi, CRIB II: An update of the clinical

PT

risk index for babies score, The Lancet 361 (9371) (2003) 17891791.
[33] L. Gagliardi, A. Cavazza, A. Brunelli, M. Battaglioli, D. Merazzi, F. Tan-

CE

doi, D. Cella, G. F. Perotti, M. Pelti, I. Stucchi, F. Frisone, A. Avanzini,

410

R. Bellu, the NNL study group, Assessing mortality risk in very low birth-

AC

weight infants: A comparison of CRIB, CRIB-II, and SNAPPE-II, Archives
of Disease in Childhood - Fetal and Neonatal Edition 89 (5) (2004) F419
F422. doi:10.1136/adc.2003.031286.

21

ACCEPTED MANUSCRIPT

AN
US

CR
IP
T

Authors Biography

415

Olli-Pekka Rinta-Koski, Lic.Sc. (Tech.), is a PhD student at the Department of Computer Science, Aalto University School of Science. His research interests are the applications of machine learning in the fields of medicine, health,

AC

CE

PT

ED

M

and well-being.

420

Simo Sarkka, D.Sc. (Tech.), is an Associate Professor and Academy Re-

search Fellow with Aalto University, Technical Advisor of IndoorAtlas Ltd., and
an Adjunct Professor with Tampere University of Technology and Lappeen-

22

ACCEPTED MANUSCRIPT

ranta Univer- sity of Technology. His research interests are in multi-sensor data
425

processing systems with applications in location sens- ing, health technology,

AN
US

CR
IP
T

machine learning, inverse problems, and brain imaging.

Jaakko Hollmen, D.Sc. (Tech.), is a senior researcher at the Department
of Computer Science, Aalto University School of Science and the group leader
430

of the Parsimonious Modelling research group at Helsinki Institute for Information Technol- ogy HIIT. The research group develops computational meth-

M

ods for data analysis with applications in cancer genomics and environmental
informatics. His research interests in- clude machine learning, data mining, and

AC

CE

PT

ED

their applications in bioinformatics and environmental time series analysis.

435

Markus Leskinen, MD, PhD, is a neonatologist at Chil- drens Hospital,
University of Helsinki, and Helsinki Univer- sity Hospital, Helsinki, Finland. He
23

ACCEPTED MANUSCRIPT

studied medicine at the University of Helsinki and specialized in pediatrics. His
re- search interests include big data in neonatology and advances in quality of
care.

AN
US

CR
IP
T

440

Sture Andersson, MD, PhD, is a pediatrician and neona- tologist by training. He is a professor of neonatology at Chil- drens Hospital, University of
Helsinki, and Helsinki Univer- sity Hospital, Helsinki, Finland. His main research areas are lung injury in preterm infants, postnatal pulmonary adapta-

M

445

AC

CE

PT

ED

tion, and big data in neonatology

24

